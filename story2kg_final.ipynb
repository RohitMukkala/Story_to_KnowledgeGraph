{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d520aeae-2e24-436f-aa59-85b39236a9ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\__msi__\\anaconda3\\envs\\story2kg_env\\python.exe\n",
      "3.10.18 | packaged by Anaconda, Inc. | (main, Jun  5 2025, 13:08:55) [MSC v.1929 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "print(sys.version)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636466ab-3441-4ec6-817c-7ff6dbdb0527",
   "metadata": {},
   "source": [
    "# Stage 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1433d3b7-1bb4-4672-b190-f1f94310d4c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sentences': [Once, a hare laughed at a tortoise for being slow., Feeling insulted, the tortoise challenged the hare to a race., At the start, the hare ran quickly and left the tortoise far behind, but he soon grew overconfident and decided to rest., While the hare slept, the tortoise kept moving steadily and, in the end, crossed the finish line first, winning the race.], 'words': [['Once', ',', 'a', 'hare', 'laughed', 'at', 'a', 'tortoise', 'for', 'being', 'slow', '.'], ['Feeling', 'insulted', ',', 'the', 'tortoise', 'challenged', 'the', 'hare', 'to', 'a', 'race', '.'], ['At', 'the', 'start', ',', 'the', 'hare', 'ran', 'quickly', 'and', 'left', 'the', 'tortoise', 'far', 'behind', ',', 'but', 'he', 'soon', 'grew', 'overconfident', 'and', 'decided', 'to', 'rest', '.'], ['While', 'the', 'hare', 'slept', ',', 'the', 'tortoise', 'kept', 'moving', 'steadily', 'and', ',', 'in', 'the', 'end', ',', 'crossed', 'the', 'finish', 'line', 'first', ',', 'winning', 'the', 'race', '.']], 'pos_tags': [[('Once', 'ADV'), (',', 'PUNCT'), ('a', 'DET'), ('hare', 'NOUN'), ('laughed', 'VERB'), ('at', 'ADP'), ('a', 'DET'), ('tortoise', 'NOUN'), ('for', 'ADP'), ('being', 'AUX'), ('slow', 'ADJ'), ('.', 'PUNCT')], [('Feeling', 'AUX'), ('insulted', 'VERB'), (',', 'PUNCT'), ('the', 'DET'), ('tortoise', 'NOUN'), ('challenged', 'VERB'), ('the', 'DET'), ('hare', 'NOUN'), ('to', 'ADP'), ('a', 'DET'), ('race', 'NOUN'), ('.', 'PUNCT')], [('At', 'ADP'), ('the', 'DET'), ('start', 'NOUN'), (',', 'PUNCT'), ('the', 'DET'), ('hare', 'NOUN'), ('ran', 'VERB'), ('quickly', 'ADV'), ('and', 'CCONJ'), ('left', 'VERB'), ('the', 'DET'), ('tortoise', 'NOUN'), ('far', 'ADV'), ('behind', 'ADV'), (',', 'PUNCT'), ('but', 'CCONJ'), ('he', 'PRON'), ('soon', 'ADV'), ('grew', 'VERB'), ('overconfident', 'ADJ'), ('and', 'CCONJ'), ('decided', 'VERB'), ('to', 'PART'), ('rest', 'VERB'), ('.', 'PUNCT')], [('While', 'SCONJ'), ('the', 'DET'), ('hare', 'NOUN'), ('slept', 'VERB'), (',', 'PUNCT'), ('the', 'DET'), ('tortoise', 'NOUN'), ('kept', 'VERB'), ('moving', 'VERB'), ('steadily', 'ADV'), ('and', 'CCONJ'), (',', 'PUNCT'), ('in', 'ADP'), ('the', 'DET'), ('end', 'NOUN'), (',', 'PUNCT'), ('crossed', 'VERB'), ('the', 'DET'), ('finish', 'NOUN'), ('line', 'NOUN'), ('first', 'ADV'), (',', 'PUNCT'), ('winning', 'VERB'), ('the', 'DET'), ('race', 'NOUN'), ('.', 'PUNCT')]], 'dependencies': [[('Once', 'advmod', 'laughed'), (',', 'punct', 'laughed'), ('a', 'det', 'hare'), ('hare', 'nsubj', 'laughed'), ('laughed', 'ROOT', 'laughed'), ('at', 'prep', 'laughed'), ('a', 'det', 'tortoise'), ('tortoise', 'pobj', 'at'), ('for', 'prep', 'laughed'), ('being', 'pcomp', 'for'), ('slow', 'acomp', 'being'), ('.', 'punct', 'laughed')], [('Feeling', 'auxpass', 'insulted'), ('insulted', 'advcl', 'challenged'), (',', 'punct', 'challenged'), ('the', 'det', 'tortoise'), ('tortoise', 'nsubj', 'challenged'), ('challenged', 'ROOT', 'challenged'), ('the', 'det', 'hare'), ('hare', 'dobj', 'challenged'), ('to', 'prep', 'challenged'), ('a', 'det', 'race'), ('race', 'pobj', 'to'), ('.', 'punct', 'challenged')], [('At', 'prep', 'ran'), ('the', 'det', 'start'), ('start', 'pobj', 'At'), (',', 'punct', 'ran'), ('the', 'det', 'hare'), ('hare', 'nsubj', 'ran'), ('ran', 'ROOT', 'ran'), ('quickly', 'advmod', 'ran'), ('and', 'cc', 'ran'), ('left', 'conj', 'ran'), ('the', 'det', 'tortoise'), ('tortoise', 'dobj', 'left'), ('far', 'advmod', 'behind'), ('behind', 'advmod', 'left'), (',', 'punct', 'ran'), ('but', 'cc', 'ran'), ('he', 'nsubj', 'grew'), ('soon', 'advmod', 'grew'), ('grew', 'conj', 'ran'), ('overconfident', 'acomp', 'grew'), ('and', 'cc', 'grew'), ('decided', 'conj', 'grew'), ('to', 'aux', 'rest'), ('rest', 'xcomp', 'decided'), ('.', 'punct', 'grew')], [('While', 'mark', 'slept'), ('the', 'det', 'hare'), ('hare', 'nsubj', 'slept'), ('slept', 'advcl', 'kept'), (',', 'punct', 'kept'), ('the', 'det', 'tortoise'), ('tortoise', 'nsubj', 'kept'), ('kept', 'ROOT', 'kept'), ('moving', 'xcomp', 'kept'), ('steadily', 'advmod', 'moving'), ('and', 'cc', 'moving'), (',', 'punct', 'crossed'), ('in', 'prep', 'crossed'), ('the', 'det', 'end'), ('end', 'pobj', 'in'), (',', 'punct', 'crossed'), ('crossed', 'conj', 'kept'), ('the', 'det', 'line'), ('finish', 'compound', 'line'), ('line', 'dobj', 'crossed'), ('first', 'advmod', 'crossed'), (',', 'punct', 'crossed'), ('winning', 'advcl', 'crossed'), ('the', 'det', 'race'), ('race', 'dobj', 'winning'), ('.', 'punct', 'crossed')]]}\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import re\n",
    "\n",
    "# Load the model once at the start of your script\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "story_text = \"\"\"\n",
    "Once, a hare laughed at a tortoise for being slow. Feeling insulted, the tortoise challenged the hare to a race. At the start, the hare ran quickly and left the tortoise far behind, but he soon grew overconfident and decided to rest. While the hare slept, the tortoise kept moving steadily and, in the end, crossed the finish line first, winning the race.\n",
    "\"\"\"\n",
    "\n",
    "def preprocess_story(text, nlp_model):\n",
    "    # --- 1. CLEANING STEP ---\n",
    "    # Normalize whitespace (replace multiple spaces/newlines with a single space)\n",
    "    clean_text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    # You could add other cleaning rules here, e.g., for special characters\n",
    "\n",
    "    # --- 2. LINGUISTIC ANALYSIS STEP ---\n",
    "    doc = nlp_model(clean_text)\n",
    "    \n",
    "    sentences = list(doc.sents)\n",
    "    words = [[token.text for token in sent if not token.is_space] for sent in doc.sents]\n",
    "    pos_tags = [[(token.text, token.pos_) for token in sent if not token.is_space] for sent in doc.sents]\n",
    "    dependencies = [[(token.text, token.dep_, token.head.text) for token in sent if not token.is_space] for sent in doc.sents]\n",
    "    \n",
    "    return {\n",
    "        \"sentences\": sentences,\n",
    "        \"words\": words,\n",
    "        \"pos_tags\": pos_tags,\n",
    "        \"dependencies\": dependencies\n",
    "    }\n",
    "\n",
    "# Example usage: pass the loaded nlp object into the function\n",
    "output = preprocess_story(story_text, nlp)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fd20d4-c014-435d-bbbf-6338f3462f0a",
   "metadata": {},
   "source": [
    "# Stage 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5204a897-423c-4a98-8267-9de21ae23832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running Coreference Resolution ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "error loading _jsonnet (this is expected on Windows), treating C:\\Users\\__msi__\\coref-spanbert-large\\config.json as plain json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resolved Text:\n",
      " \n",
      " Once , a hare laughed at a tortoise for being slow . Feeling insulted , a tortoise challenged a hare to a race . At the start , a hare ran quickly and left a tortoise far behind , but a hare soon grew overconfident and decided to rest . While a hare slept , a tortoise kept moving steadily and , in the end , crossed the finish line first , winning a race . \n",
      "\n",
      "----------------------------------------\n",
      "--- Running Stage 1 ---\n",
      "Stage 1 Sentences:\n",
      " ['Once , a hare laughed at a tortoise for being slow .', 'Feeling insulted , a tortoise challenged a hare to a race .', 'At the start , a hare ran quickly and left a tortoise far behind , but a hare soon grew overconfident and decided to rest .', 'While a hare slept , a tortoise kept moving steadily and , in the end , crossed the finish line first , winning a race .']\n",
      "----------------------------------------\n",
      "--- Running Stage 2 ---\n",
      "Final Stage 2 Output:\n",
      " ['b scene [Once , a hare laughed at a tortoise for being slow .]', 'b scene [Feeling insulted , a tortoise challenged a hare to a race .]', 'b scene [At the start , a hare ran quickly and left a tortoise far behind , but a hare soon grew overconfident and decided to rest .]', 'i scene [While a hare slept , a tortoise kept moving steadily and , in the end , crossed the finish line first , winning a race .]']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import re\n",
    "from allennlp.predictors.predictor import Predictor\n",
    "import allennlp_models.coref\n",
    "\n",
    "# ==============================================================================\n",
    "# LOAD MODELS ONCE\n",
    "# ==============================================================================\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "# ==============================================================================\n",
    "# COREFERENCE RESOLUTION (robust replacement)\n",
    "# ==============================================================================\n",
    "from allennlp.predictors.predictor import Predictor\n",
    "import allennlp_models.coref\n",
    "\n",
    "def resolve_coreferences(text, model_path):\n",
    "    predictor = Predictor.from_path(model_path)\n",
    "    prediction = predictor.predict(document=text)\n",
    "\n",
    "    tokens = prediction[\"document\"]\n",
    "    clusters = prediction[\"clusters\"]\n",
    "\n",
    "    # Convert tokens back to text positions\n",
    "    resolved_text = tokens[:]  # copy\n",
    "\n",
    "    for cluster in clusters:\n",
    "        main_mention = \" \".join(tokens[cluster[0][0]: cluster[0][1] + 1])\n",
    "        for mention in cluster[1:]:\n",
    "            start, end = mention\n",
    "            # Replace the pronoun directly\n",
    "            resolved_text[start] = main_mention\n",
    "            for i in range(start + 1, end + 1):\n",
    "                resolved_text[i] = \"\"\n",
    "\n",
    "    return \" \".join([t for t in resolved_text if t != \"\"])\n",
    "\n",
    "\n",
    "    # tokens = prediction[\"document\"]\n",
    "    # clusters = prediction[\"clusters\"]\n",
    "\n",
    "    # # Build replacement map: (start, end) → main_mention\n",
    "    # replacements = {}\n",
    "    # for cluster in clusters:\n",
    "    #     main_mention = \" \".join(tokens[cluster[0][0] : cluster[0][1] + 1])\n",
    "    #     for mention in cluster[1:]:\n",
    "    #         replacements[(mention[0], mention[1])] = main_mention\n",
    "\n",
    "    # resolved_tokens = []\n",
    "    # skip_until = -1\n",
    "    # for i, token in enumerate(tokens):\n",
    "    #     if i < skip_until:\n",
    "    #         continue\n",
    "    #     replaced = False\n",
    "    #     for (start, end), main in replacements.items():\n",
    "    #         if i == start:\n",
    "    #             resolved_tokens.append(main)\n",
    "    #             skip_until = end + 1\n",
    "    #             replaced = True\n",
    "    #             break\n",
    "    #     if not replaced:\n",
    "    #         resolved_tokens.append(token)\n",
    "\n",
    "    # return \" \".join(resolved_tokens)\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# STAGE 1: Preprocess & Analyze Text\n",
    "# ==============================================================================\n",
    "def preprocess_story(text, nlp_model):\n",
    "    clean_text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    doc = nlp_model(clean_text)\n",
    "    return {\n",
    "        \"sentences\": list(doc.sents),\n",
    "        \"dependencies\": [\n",
    "            [(token.text, token.dep_, token.head.text) for token in sent if not token.is_space]\n",
    "            for sent in doc.sents\n",
    "        ]\n",
    "    }\n",
    "\n",
    "# ==============================================================================\n",
    "# STAGE 2: Scene Annotation (robust subject tracking)\n",
    "# ==============================================================================\n",
    "def get_sentence_subject(sentence_dependencies):\n",
    "    for token, dep, head in sentence_dependencies:\n",
    "        if dep == \"nsubj\":\n",
    "            return token\n",
    "    return None\n",
    "\n",
    "def annotate_scenes(stage1_output):\n",
    "    annotated_sentences = []\n",
    "    last_subject = None\n",
    "    sentences_text = [sent.text for sent in stage1_output[\"sentences\"]]\n",
    "    dependencies = stage1_output[\"dependencies\"]\n",
    "\n",
    "    for i, sent_text in enumerate(sentences_text):\n",
    "        current_subject = get_sentence_subject(dependencies[i])\n",
    "\n",
    "        if i == 0 or (current_subject and current_subject != last_subject):\n",
    "            tag = \"b scene\"\n",
    "        else:\n",
    "            tag = \"i scene\"\n",
    "\n",
    "        annotated_sentences.append(f\"{tag} [{sent_text}]\")\n",
    "\n",
    "        if current_subject:\n",
    "            last_subject = current_subject\n",
    "\n",
    "    return annotated_sentences\n",
    "\n",
    "# ==============================================================================\n",
    "# MAIN PIPELINE\n",
    "# ==============================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    # story_text = \"\"\"\n",
    "    # Hare was hopping through the forest.\n",
    "    # He saw a tortoise slowly walking along the path.\n",
    "    # Then he greeted the tortoise warmly.\n",
    "    # \"\"\"\n",
    "\n",
    "    coref_model_path = \"C:/Users/__msi__/coref-spanbert-large\"\n",
    "\n",
    "    print(\"--- Running Coreference Resolution ---\")\n",
    "    resolved_text = resolve_coreferences(story_text, coref_model_path)\n",
    "    print(\"Resolved Text:\\n\", resolved_text)\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    print(\"--- Running Stage 1 ---\")\n",
    "    stage1_data = preprocess_story(resolved_text, nlp)\n",
    "    print(\"Stage 1 Sentences:\\n\", [s.text for s in stage1_data[\"sentences\"]])\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    print(\"--- Running Stage 2 ---\")\n",
    "    stage2_output = annotate_scenes(stage1_data)\n",
    "    print(\"Final Stage 2 Output:\\n\", stage2_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a483c100-0cd3-4f3a-a099-3586b1f0740d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"scene_id\": 1,\n",
      "    \"text\": \"Once , a hare laughed at a tortoise for being slow .\",\n",
      "    \"tokens\": [\n",
      "      \"Once\",\n",
      "      \",\",\n",
      "      \"a\",\n",
      "      \"hare\",\n",
      "      \"laughed\",\n",
      "      \"at\",\n",
      "      \"a\",\n",
      "      \"tortoise\",\n",
      "      \"for\",\n",
      "      \"being\",\n",
      "      \"slow\",\n",
      "      \".\"\n",
      "    ],\n",
      "    \"pos\": [\n",
      "      \"ADV\",\n",
      "      \"PUNCT\",\n",
      "      \"DET\",\n",
      "      \"NOUN\",\n",
      "      \"VERB\",\n",
      "      \"ADP\",\n",
      "      \"DET\",\n",
      "      \"NOUN\",\n",
      "      \"ADP\",\n",
      "      \"AUX\",\n",
      "      \"ADJ\",\n",
      "      \"PUNCT\"\n",
      "    ],\n",
      "    \"dependencies\": [\n",
      "      [\n",
      "        \"Once\",\n",
      "        \"advmod\",\n",
      "        \"laughed\"\n",
      "      ],\n",
      "      [\n",
      "        \",\",\n",
      "        \"punct\",\n",
      "        \"laughed\"\n",
      "      ],\n",
      "      [\n",
      "        \"a\",\n",
      "        \"det\",\n",
      "        \"hare\"\n",
      "      ],\n",
      "      [\n",
      "        \"hare\",\n",
      "        \"nsubj\",\n",
      "        \"laughed\"\n",
      "      ],\n",
      "      [\n",
      "        \"laughed\",\n",
      "        \"ROOT\",\n",
      "        \"laughed\"\n",
      "      ],\n",
      "      [\n",
      "        \"at\",\n",
      "        \"prep\",\n",
      "        \"laughed\"\n",
      "      ],\n",
      "      [\n",
      "        \"a\",\n",
      "        \"det\",\n",
      "        \"tortoise\"\n",
      "      ],\n",
      "      [\n",
      "        \"tortoise\",\n",
      "        \"pobj\",\n",
      "        \"at\"\n",
      "      ],\n",
      "      [\n",
      "        \"for\",\n",
      "        \"prep\",\n",
      "        \"laughed\"\n",
      "      ],\n",
      "      [\n",
      "        \"being\",\n",
      "        \"pcomp\",\n",
      "        \"for\"\n",
      "      ],\n",
      "      [\n",
      "        \"slow\",\n",
      "        \"acomp\",\n",
      "        \"being\"\n",
      "      ],\n",
      "      [\n",
      "        \".\",\n",
      "        \"punct\",\n",
      "        \"laughed\"\n",
      "      ]\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"scene_id\": 2,\n",
      "    \"text\": \"Feeling insulted , a tortoise challenged a hare to a race .\",\n",
      "    \"tokens\": [\n",
      "      \"Feeling\",\n",
      "      \"insulted\",\n",
      "      \",\",\n",
      "      \"a\",\n",
      "      \"tortoise\",\n",
      "      \"challenged\",\n",
      "      \"a\",\n",
      "      \"hare\",\n",
      "      \"to\",\n",
      "      \"a\",\n",
      "      \"race\",\n",
      "      \".\"\n",
      "    ],\n",
      "    \"pos\": [\n",
      "      \"AUX\",\n",
      "      \"VERB\",\n",
      "      \"PUNCT\",\n",
      "      \"DET\",\n",
      "      \"NOUN\",\n",
      "      \"VERB\",\n",
      "      \"DET\",\n",
      "      \"NOUN\",\n",
      "      \"ADP\",\n",
      "      \"DET\",\n",
      "      \"NOUN\",\n",
      "      \"PUNCT\"\n",
      "    ],\n",
      "    \"dependencies\": [\n",
      "      [\n",
      "        \"Feeling\",\n",
      "        \"auxpass\",\n",
      "        \"insulted\"\n",
      "      ],\n",
      "      [\n",
      "        \"insulted\",\n",
      "        \"advcl\",\n",
      "        \"challenged\"\n",
      "      ],\n",
      "      [\n",
      "        \",\",\n",
      "        \"punct\",\n",
      "        \"challenged\"\n",
      "      ],\n",
      "      [\n",
      "        \"a\",\n",
      "        \"det\",\n",
      "        \"tortoise\"\n",
      "      ],\n",
      "      [\n",
      "        \"tortoise\",\n",
      "        \"nsubj\",\n",
      "        \"challenged\"\n",
      "      ],\n",
      "      [\n",
      "        \"challenged\",\n",
      "        \"ROOT\",\n",
      "        \"challenged\"\n",
      "      ],\n",
      "      [\n",
      "        \"a\",\n",
      "        \"det\",\n",
      "        \"hare\"\n",
      "      ],\n",
      "      [\n",
      "        \"hare\",\n",
      "        \"dobj\",\n",
      "        \"challenged\"\n",
      "      ],\n",
      "      [\n",
      "        \"to\",\n",
      "        \"prep\",\n",
      "        \"challenged\"\n",
      "      ],\n",
      "      [\n",
      "        \"a\",\n",
      "        \"det\",\n",
      "        \"race\"\n",
      "      ],\n",
      "      [\n",
      "        \"race\",\n",
      "        \"pobj\",\n",
      "        \"to\"\n",
      "      ],\n",
      "      [\n",
      "        \".\",\n",
      "        \"punct\",\n",
      "        \"challenged\"\n",
      "      ]\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"scene_id\": 3,\n",
      "    \"text\": \"At the start , a hare ran quickly and left a tortoise far behind , but a hare soon grew overconfident and decided to rest .\",\n",
      "    \"tokens\": [\n",
      "      \"At\",\n",
      "      \"the\",\n",
      "      \"start\",\n",
      "      \",\",\n",
      "      \"a\",\n",
      "      \"hare\",\n",
      "      \"ran\",\n",
      "      \"quickly\",\n",
      "      \"and\",\n",
      "      \"left\",\n",
      "      \"a\",\n",
      "      \"tortoise\",\n",
      "      \"far\",\n",
      "      \"behind\",\n",
      "      \",\",\n",
      "      \"but\",\n",
      "      \"a\",\n",
      "      \"hare\",\n",
      "      \"soon\",\n",
      "      \"grew\",\n",
      "      \"overconfident\",\n",
      "      \"and\",\n",
      "      \"decided\",\n",
      "      \"to\",\n",
      "      \"rest\",\n",
      "      \".\"\n",
      "    ],\n",
      "    \"pos\": [\n",
      "      \"ADP\",\n",
      "      \"DET\",\n",
      "      \"NOUN\",\n",
      "      \"PUNCT\",\n",
      "      \"DET\",\n",
      "      \"NOUN\",\n",
      "      \"VERB\",\n",
      "      \"ADV\",\n",
      "      \"CCONJ\",\n",
      "      \"VERB\",\n",
      "      \"DET\",\n",
      "      \"NOUN\",\n",
      "      \"ADV\",\n",
      "      \"ADV\",\n",
      "      \"PUNCT\",\n",
      "      \"CCONJ\",\n",
      "      \"DET\",\n",
      "      \"NOUN\",\n",
      "      \"ADV\",\n",
      "      \"VERB\",\n",
      "      \"ADJ\",\n",
      "      \"CCONJ\",\n",
      "      \"VERB\",\n",
      "      \"PART\",\n",
      "      \"VERB\",\n",
      "      \"PUNCT\"\n",
      "    ],\n",
      "    \"dependencies\": [\n",
      "      [\n",
      "        \"At\",\n",
      "        \"prep\",\n",
      "        \"ran\"\n",
      "      ],\n",
      "      [\n",
      "        \"the\",\n",
      "        \"det\",\n",
      "        \"start\"\n",
      "      ],\n",
      "      [\n",
      "        \"start\",\n",
      "        \"pobj\",\n",
      "        \"At\"\n",
      "      ],\n",
      "      [\n",
      "        \",\",\n",
      "        \"punct\",\n",
      "        \"ran\"\n",
      "      ],\n",
      "      [\n",
      "        \"a\",\n",
      "        \"det\",\n",
      "        \"hare\"\n",
      "      ],\n",
      "      [\n",
      "        \"hare\",\n",
      "        \"nsubj\",\n",
      "        \"ran\"\n",
      "      ],\n",
      "      [\n",
      "        \"ran\",\n",
      "        \"ROOT\",\n",
      "        \"ran\"\n",
      "      ],\n",
      "      [\n",
      "        \"quickly\",\n",
      "        \"advmod\",\n",
      "        \"ran\"\n",
      "      ],\n",
      "      [\n",
      "        \"and\",\n",
      "        \"cc\",\n",
      "        \"ran\"\n",
      "      ],\n",
      "      [\n",
      "        \"left\",\n",
      "        \"conj\",\n",
      "        \"ran\"\n",
      "      ],\n",
      "      [\n",
      "        \"a\",\n",
      "        \"det\",\n",
      "        \"tortoise\"\n",
      "      ],\n",
      "      [\n",
      "        \"tortoise\",\n",
      "        \"dobj\",\n",
      "        \"left\"\n",
      "      ],\n",
      "      [\n",
      "        \"far\",\n",
      "        \"advmod\",\n",
      "        \"behind\"\n",
      "      ],\n",
      "      [\n",
      "        \"behind\",\n",
      "        \"advmod\",\n",
      "        \"left\"\n",
      "      ],\n",
      "      [\n",
      "        \",\",\n",
      "        \"punct\",\n",
      "        \"ran\"\n",
      "      ],\n",
      "      [\n",
      "        \"but\",\n",
      "        \"cc\",\n",
      "        \"ran\"\n",
      "      ],\n",
      "      [\n",
      "        \"a\",\n",
      "        \"det\",\n",
      "        \"hare\"\n",
      "      ],\n",
      "      [\n",
      "        \"hare\",\n",
      "        \"nsubj\",\n",
      "        \"grew\"\n",
      "      ],\n",
      "      [\n",
      "        \"soon\",\n",
      "        \"advmod\",\n",
      "        \"grew\"\n",
      "      ],\n",
      "      [\n",
      "        \"grew\",\n",
      "        \"conj\",\n",
      "        \"ran\"\n",
      "      ],\n",
      "      [\n",
      "        \"overconfident\",\n",
      "        \"acomp\",\n",
      "        \"grew\"\n",
      "      ],\n",
      "      [\n",
      "        \"and\",\n",
      "        \"cc\",\n",
      "        \"grew\"\n",
      "      ],\n",
      "      [\n",
      "        \"decided\",\n",
      "        \"conj\",\n",
      "        \"grew\"\n",
      "      ],\n",
      "      [\n",
      "        \"to\",\n",
      "        \"aux\",\n",
      "        \"rest\"\n",
      "      ],\n",
      "      [\n",
      "        \"rest\",\n",
      "        \"xcomp\",\n",
      "        \"decided\"\n",
      "      ],\n",
      "      [\n",
      "        \".\",\n",
      "        \"punct\",\n",
      "        \"grew\"\n",
      "      ]\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"scene_id\": 4,\n",
      "    \"text\": \"While a hare slept , a tortoise kept moving steadily and , in the end , crossed the finish line first , winning a race .\",\n",
      "    \"tokens\": [\n",
      "      \"While\",\n",
      "      \"a\",\n",
      "      \"hare\",\n",
      "      \"slept\",\n",
      "      \",\",\n",
      "      \"a\",\n",
      "      \"tortoise\",\n",
      "      \"kept\",\n",
      "      \"moving\",\n",
      "      \"steadily\",\n",
      "      \"and\",\n",
      "      \",\",\n",
      "      \"in\",\n",
      "      \"the\",\n",
      "      \"end\",\n",
      "      \",\",\n",
      "      \"crossed\",\n",
      "      \"the\",\n",
      "      \"finish\",\n",
      "      \"line\",\n",
      "      \"first\",\n",
      "      \",\",\n",
      "      \"winning\",\n",
      "      \"a\",\n",
      "      \"race\",\n",
      "      \".\"\n",
      "    ],\n",
      "    \"pos\": [\n",
      "      \"SCONJ\",\n",
      "      \"DET\",\n",
      "      \"NOUN\",\n",
      "      \"VERB\",\n",
      "      \"PUNCT\",\n",
      "      \"DET\",\n",
      "      \"NOUN\",\n",
      "      \"VERB\",\n",
      "      \"VERB\",\n",
      "      \"ADV\",\n",
      "      \"CCONJ\",\n",
      "      \"PUNCT\",\n",
      "      \"ADP\",\n",
      "      \"DET\",\n",
      "      \"NOUN\",\n",
      "      \"PUNCT\",\n",
      "      \"VERB\",\n",
      "      \"DET\",\n",
      "      \"NOUN\",\n",
      "      \"NOUN\",\n",
      "      \"ADV\",\n",
      "      \"PUNCT\",\n",
      "      \"VERB\",\n",
      "      \"DET\",\n",
      "      \"NOUN\",\n",
      "      \"PUNCT\"\n",
      "    ],\n",
      "    \"dependencies\": [\n",
      "      [\n",
      "        \"While\",\n",
      "        \"mark\",\n",
      "        \"slept\"\n",
      "      ],\n",
      "      [\n",
      "        \"a\",\n",
      "        \"det\",\n",
      "        \"hare\"\n",
      "      ],\n",
      "      [\n",
      "        \"hare\",\n",
      "        \"nsubj\",\n",
      "        \"slept\"\n",
      "      ],\n",
      "      [\n",
      "        \"slept\",\n",
      "        \"advcl\",\n",
      "        \"kept\"\n",
      "      ],\n",
      "      [\n",
      "        \",\",\n",
      "        \"punct\",\n",
      "        \"kept\"\n",
      "      ],\n",
      "      [\n",
      "        \"a\",\n",
      "        \"det\",\n",
      "        \"tortoise\"\n",
      "      ],\n",
      "      [\n",
      "        \"tortoise\",\n",
      "        \"nsubj\",\n",
      "        \"kept\"\n",
      "      ],\n",
      "      [\n",
      "        \"kept\",\n",
      "        \"ROOT\",\n",
      "        \"kept\"\n",
      "      ],\n",
      "      [\n",
      "        \"moving\",\n",
      "        \"xcomp\",\n",
      "        \"kept\"\n",
      "      ],\n",
      "      [\n",
      "        \"steadily\",\n",
      "        \"advmod\",\n",
      "        \"moving\"\n",
      "      ],\n",
      "      [\n",
      "        \"and\",\n",
      "        \"cc\",\n",
      "        \"moving\"\n",
      "      ],\n",
      "      [\n",
      "        \",\",\n",
      "        \"punct\",\n",
      "        \"crossed\"\n",
      "      ],\n",
      "      [\n",
      "        \"in\",\n",
      "        \"prep\",\n",
      "        \"crossed\"\n",
      "      ],\n",
      "      [\n",
      "        \"the\",\n",
      "        \"det\",\n",
      "        \"end\"\n",
      "      ],\n",
      "      [\n",
      "        \"end\",\n",
      "        \"pobj\",\n",
      "        \"in\"\n",
      "      ],\n",
      "      [\n",
      "        \",\",\n",
      "        \"punct\",\n",
      "        \"crossed\"\n",
      "      ],\n",
      "      [\n",
      "        \"crossed\",\n",
      "        \"conj\",\n",
      "        \"kept\"\n",
      "      ],\n",
      "      [\n",
      "        \"the\",\n",
      "        \"det\",\n",
      "        \"line\"\n",
      "      ],\n",
      "      [\n",
      "        \"finish\",\n",
      "        \"compound\",\n",
      "        \"line\"\n",
      "      ],\n",
      "      [\n",
      "        \"line\",\n",
      "        \"dobj\",\n",
      "        \"crossed\"\n",
      "      ],\n",
      "      [\n",
      "        \"first\",\n",
      "        \"advmod\",\n",
      "        \"crossed\"\n",
      "      ],\n",
      "      [\n",
      "        \",\",\n",
      "        \"punct\",\n",
      "        \"crossed\"\n",
      "      ],\n",
      "      [\n",
      "        \"winning\",\n",
      "        \"advcl\",\n",
      "        \"crossed\"\n",
      "      ],\n",
      "      [\n",
      "        \"a\",\n",
      "        \"det\",\n",
      "        \"race\"\n",
      "      ],\n",
      "      [\n",
      "        \"race\",\n",
      "        \"dobj\",\n",
      "        \"winning\"\n",
      "      ],\n",
      "      [\n",
      "        \".\",\n",
      "        \"punct\",\n",
      "        \"crossed\"\n",
      "      ]\n",
      "    ]\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "def convert_stage2_to_stage3(stage1_output, stage2_output):\n",
    "    stage3_input = []\n",
    "    \n",
    "    for i, scene_str in enumerate(stage2_output, start=1):\n",
    "        # Remove \"b scene\" / \"i scene\" wrappers\n",
    "        clean_text = re.sub(r'^[bi]\\s+scene\\s+\\[|\\]$', '', scene_str).strip()\n",
    "\n",
    "        # Grab sentence object + deps from Stage 1\n",
    "        sent = stage1_output[\"sentences\"][i-1]\n",
    "        deps = stage1_output[\"dependencies\"][i-1]\n",
    "\n",
    "        tokens = [tok.text for tok in sent if not tok.is_space]\n",
    "        pos_tags = [tok.pos_ for tok in sent if not tok.is_space]\n",
    "\n",
    "        stage3_input.append({\n",
    "            \"scene_id\": i,\n",
    "            \"text\": clean_text,\n",
    "            \"tokens\": tokens,\n",
    "            \"pos\": pos_tags,\n",
    "            \"dependencies\": deps\n",
    "        })\n",
    "    \n",
    "    return stage3_input\n",
    "\n",
    "# After running Stage 1 + Stage 2\n",
    "stage3_ready_input = convert_stage2_to_stage3(stage1_data, stage2_output)\n",
    "\n",
    "import json\n",
    "print(json.dumps(stage3_ready_input, indent=2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc842c30-9b9d-4b00-951d-841906ecff1b",
   "metadata": {},
   "source": [
    "# Stage 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "511519ec-d690-4912-9300-ac962a6b598f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading models...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "error loading _jsonnet (this is expected on Windows), treating C:\\Users\\__msi__\\coref-spanbert-large\\config.json as plain json\n",
      "error loading _jsonnet (this is expected on Windows), treating C:\\Users\\__msi__\\AppData\\Local\\Temp\\tmpfya2wp_1\\config.json as plain json\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models loaded.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import spacy\n",
    "import json\n",
    "from transformers import pipeline\n",
    "from allennlp.predictors.predictor import Predictor\n",
    "import allennlp_models.tagging\n",
    "import allennlp_models.structured_prediction # Added for SRL\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. LOAD MODELS ONCE\n",
    "# ==============================================================================\n",
    "print(\"Loading models...\")\n",
    "# --- Core Models ---\n",
    "coref_predictor = Predictor.from_path(\"C:/Users/__msi__/coref-spanbert-large\")\n",
    "ner_pipeline = pipeline(\"ner\", model=\"C:/Users/__msi__/ner-model-large\", aggregation_strategy=\"simple\")\n",
    "emotion_classifier = pipeline(\"text-classification\", model=\"C:/Users/__msi__/emotion-model-local\", top_k=1)\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# --- NEW: Event Extraction Model (SRL) ---\n",
    "srl_predictor = Predictor.from_path(\n",
    "    \"https://storage.googleapis.com/allennlp-public-models/structured-prediction-srl-bert.2020.12.15.tar.gz\"\n",
    ")\n",
    "print(\"Models loaded.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50e25756-94f3-4b21-b093-2b4e7e2c921f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==============================================================================\n",
    "# 2. EVENT SCHEMA AND MAPPING\n",
    "# ==============================================================================\n",
    "general_event_schema = {\n",
    "    \"Conflict\": {\n",
    "        \"triggers\": [\"fought\", \"argued\", \"attacked\", \"defended\", \"competed\", \"defeated\"],\n",
    "        \"roles\": {\"ARG0\": \"Protagonist\",\"ARG1\": \"Antagonist\",\"ARGM-MNR\": \"Outcome\"}\n",
    "    },\n",
    "    \"Journey\": {\n",
    "        \"triggers\": [\"traveled\", \"went\", \"journeyed\", \"arrived\", \"departed\", \"fled\"],\n",
    "        \"roles\": {\"ARG0\": \"Traveler\",\"ARGM-LOC\": \"Origin\",\"ARGM-DIR\": \"Destination\"}\n",
    "    },\n",
    "    \"Transaction\": {\n",
    "        \"triggers\": [\"gave\", \"received\", \"bought\", \"sold\", \"traded\", \"stole\"],\n",
    "        \"roles\": {\"ARG0\": \"Giver\",\"ARG1\": \"Item\",\"ARG2\": \"Recipient\"}\n",
    "    },\n",
    "    \"Communication\": {\n",
    "        \"triggers\": [\"said\", \"told\", \"laughed\", \"boasted\", \"asked\", \"yelled\", \"whispered\"],\n",
    "        \"roles\": {\"ARG0\": \"Speaker\",\"ARG1\": \"Message\",\"ARG2\": \"Listener\"}\n",
    "    },\n",
    "    \"Perception\": {\n",
    "        \"triggers\": [\"saw\", \"heard\", \"watched\", \"noticed\", \"observed\", \"sensed\", \"smelled\"],\n",
    "        \"roles\": {\"ARG0\": \"Observer\",\"ARG1\": \"Phenomenon\"}\n",
    "    },\n",
    "        \"Cognition\": {\n",
    "        \"triggers\": [\"thought\", \"believed\", \"knew\", \"realized\", \"wondered\", \"decided\", \"forgot\"],\n",
    "        \"roles\": {\"ARG0\": \"Cognizer\",\"ARG1\": \"Content\"}\n",
    "    },\n",
    "    \"Creation\": {\n",
    "        \"triggers\": [\"built\", \"made\", \"created\", \"wrote\", \"painted\", \"designed\", \"composed\"],\n",
    "        \"roles\": {\"ARG0\": \"Creator\",\"ARG1\": \"Creation\"}\n",
    "    },\n",
    "    \"Destruction\": {\n",
    "        \"triggers\": [\"destroyed\", \"broke\", \"ruined\", \"shattered\", \"demolished\", \"tore\"],\n",
    "        \"roles\": {\"ARG0\": \"Destroyer\",\"ARG1\": \"Object\"}\n",
    "    },\n",
    "    \"Motion\": {\n",
    "        \"triggers\": [\"moved\", \"ran\", \"walked\", \"flew\", \"swam\", \"hopped\", \"crawled\"],\n",
    "        \"roles\": {\"ARG0\": \"Mover\",\"ARGM-LOC\": \"Path\"}\n",
    "    },\n",
    "    \"Possession\": {\n",
    "        \"triggers\": [\"had\", \"owned\", \"possessed\", \"held\"],\n",
    "        \"roles\": {\"ARG0\": \"Owner\",\"ARG1\": \"Possession\"}\n",
    "    },\n",
    "    \"Life_Event\": {\n",
    "        \"triggers\": [\"born\", \"died\", \"married\", \"graduated\", \"became king\", \"crowned\"],\n",
    "        \"roles\": {\"ARG0\": \"Person\",\"ARGM-LOC\": \"Location\"}\n",
    "    },\n",
    "    \"Control\": {\n",
    "        \"triggers\": [\"ruled\", \"controlled\", \"commanded\", \"led\", \"governed\"],\n",
    "        \"roles\": {\"ARG0\": \"Controller\",\"ARG1\": \"Domain\"}\n",
    "    },\n",
    "    \"Emotion_Expression\": {\n",
    "        \"triggers\": [\"loved\", \"hated\", \"feared\", \"enjoyed\", \"cried\", \"smiled\"],\n",
    "        \"roles\": {\"ARG0\": \"Experiencer\",\"ARG1\": \"Stimulus\"}\n",
    "    },\n",
    "     \"Assistance\": {\n",
    "        \"triggers\": [\"helped\", \"assisted\", \"saved\", \"rescued\", \"supported\"],\n",
    "        \"roles\": {\"ARG0\": \"Helper\",\"ARG1\": \"Recipient\",\"ARG2\": \"Task\"}\n",
    "    },\n",
    "    \"Consumption\": {\n",
    "        \"triggers\": [\"ate\", \"drank\", \"consumed\", \"used\"],\n",
    "        \"roles\": {\"ARG0\": \"Consumer\",\"ARG1\": \"Consumable\"}\n",
    "    },\n",
    "    \"Inspection\": {\n",
    "        \"triggers\": [\"investigated\", \"examined\", \"inspected\", \"searched\", \"looked for\"],\n",
    "        \"roles\": {\"ARG0\": \"Investigator\",\"ARG1\": \"Subject\"}\n",
    "    },\n",
    "    \"Social\": {\n",
    "        \"triggers\": [\"met\", \"gathered\", \"celebrated\", \"partied\", \"dined\"],\n",
    "        \"roles\": {\"ARG0\": \"Participant_1\",\"ARG1\": \"Participant_2\",\"ARGM-PRD\": \"Event\"}\n",
    "    },\n",
    "    \"Transformation\": {\n",
    "        \"triggers\": [\"became\", \"transformed\", \"changed into\", \"turned into\"],\n",
    "        \"roles\": {\"ARG0\": \"Entity\",\"ARG1\": \"Final_State\"}\n",
    "    },\n",
    "    \"Causation\": {\n",
    "        \"triggers\": [\"caused\", \"made\", \"forced\", \"led to\", \"resulted in\"],\n",
    "        \"roles\": {\"ARG0\": \"Cause\",\"ARG1\": \"Effect\"}\n",
    "    }\n",
    "}\n",
    "\n",
    "# --- Build a fast lemma→schema lookup ---\n",
    "event_mapping = {}\n",
    "for event_type, details in general_event_schema.items():\n",
    "    for trigger_lemma in details[\"triggers\"]:\n",
    "        event_mapping[trigger_lemma] = {\n",
    "            \"event_type\": event_type,\n",
    "            \"role_map\": details[\"roles\"]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2eeebee-925a-4621-883f-b7cc6eb6c79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# 3. HYBRID NER FUNCTION (Unchanged)\n",
    "# ==============================================================================\n",
    "def extract_entities_solved(sentence_text, known_characters):\n",
    "    def normalize_text(chunk):\n",
    "        if len(chunk) > 1 and chunk[0].pos_ == \"DET\":\n",
    "            return chunk[1:].text\n",
    "        return chunk.text\n",
    "\n",
    "    ner_results = ner_pipeline(sentence_text)\n",
    "    entities = []\n",
    "    seen_words = set()\n",
    "\n",
    "    for ent in ner_results:\n",
    "        entities.append({\n",
    "            \"entity_group\": ent[\"entity_group\"], \"word\": ent[\"word\"],\n",
    "            \"score\": round(ent[\"score\"], 4), \"source\": \"NER\"\n",
    "        })\n",
    "        for word in ent[\"word\"].split():\n",
    "            seen_words.add(word.lower())\n",
    "\n",
    "    doc = nlp(sentence_text)\n",
    "    for chunk in doc.noun_chunks:\n",
    "        normalized_word = normalize_text(chunk)\n",
    "        if chunk.root.text.lower() not in seen_words:\n",
    "            dep = chunk.root.dep_\n",
    "            ent_type = \"MISC\"\n",
    "            if normalized_word.lower() in known_characters:\n",
    "                ent_type = \"Character\"\n",
    "            elif dep in [\"nsubj\", \"nsubjpass\"]:\n",
    "                ent_type = \"Character\"\n",
    "                known_characters.add(normalized_word.lower())\n",
    "            elif dep in [\"dobj\"]:\n",
    "                ent_type = \"Object\"\n",
    "            elif dep in [\"pobj\", \"obl\"]:\n",
    "                ent_type = \"Location\"\n",
    "\n",
    "            entities.append({\n",
    "                \"entity_group\": ent_type, \"word\": normalized_word,\n",
    "                \"score\": 1.0, \"source\": \"Rule\"\n",
    "            })\n",
    "            for token in chunk:\n",
    "                seen_words.add(token.text.lower())\n",
    "    \n",
    "    entity_map = {}\n",
    "    type_priority = {\"Character\": 3, \"Person\": 2, \"Location\": 1, \"Object\": 0, \"MISC\": -1}\n",
    "    for ent in entities:\n",
    "        word_key = ent[\"word\"].lower()\n",
    "        current_type = ent[\"entity_group\"]\n",
    "        if word_key in entity_map:\n",
    "            existing_type = entity_map[word_key][\"entity_group\"]\n",
    "            if type_priority.get(current_type, -1) > type_priority.get(existing_type, -1):\n",
    "                entity_map[word_key] = ent\n",
    "        else:\n",
    "            entity_map[word_key] = ent\n",
    "            \n",
    "    final_entities = list(entity_map.values())\n",
    "    tag_mapping = {\n",
    "        \"PER\": \"Person\", \"LOC\": \"Location\", \"ORG\": \"Organization\",\n",
    "        \"CHAR\": \"Character\", \"OBJ\": \"Object\", \"MISC\": \"Miscellaneous\"\n",
    "    }\n",
    "    \n",
    "    for ent in final_entities:\n",
    "        original_group = ent[\"entity_group\"]\n",
    "        ent[\"entity_group\"] = tag_mapping.get(original_group, original_group)\n",
    "\n",
    "    return final_entities, known_characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1951afe-b3c6-4fd7-ac57-6a2ab4e165cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_attributes_improved(scene):\n",
    "    \"\"\"\n",
    "    Extracts attributes and correctly links them to their semantic entity,\n",
    "    handling cases like \"tortoise is handsome\" by finding the subject of the verb.\n",
    "    \"\"\"\n",
    "    attributes = {}\n",
    "    tokens = scene.get(\"tokens\", [])\n",
    "    dependencies = scene.get(\"dependencies\", [])\n",
    "\n",
    "    # Create more useful lookups for easier tree traversal\n",
    "    # 1. Map each token to its head and dependency type\n",
    "    token_to_head = {t: (h, d) for t, d, h in dependencies}\n",
    "    # 2. Map each head to its children tokens and their dependency types\n",
    "    head_to_children = {}\n",
    "    for t, d, h in dependencies:\n",
    "        if h not in head_to_children:\n",
    "            head_to_children[h] = []\n",
    "        head_to_children[h].append((t, d))\n",
    "\n",
    "    for token in tokens:\n",
    "        if token not in token_to_head:\n",
    "            continue\n",
    "\n",
    "        head, dep = token_to_head[token]\n",
    "\n",
    "        # Check if the token is an attribute we care about\n",
    "        if dep in {\"amod\", \"advmod\", \"acomp\", \"xcomp\", \"oprd\"}:\n",
    "            final_head = head\n",
    "\n",
    "            # --- THE CORE IMPROVEMENT ---\n",
    "            # If the attribute is an adjectival complement (acomp) or open clausal\n",
    "            # complement (xcomp), its head is a verb. We need to find the *subject*\n",
    "            # of that verb to find the entity being described.\n",
    "            if dep in {\"acomp\", \"xcomp\"}:\n",
    "                if head in head_to_children:\n",
    "                    # Search for the nominal subject (nsubj) of the verb\n",
    "                    for child, child_dep in head_to_children[head]:\n",
    "                        if child_dep in {\"nsubj\", \"nsubjpass\"}:\n",
    "                            final_head = child\n",
    "                            break # Found the subject, stop looking\n",
    "\n",
    "            # Assign the attribute (token) to its true head (final_head)\n",
    "            if final_head not in attributes:\n",
    "                attributes[final_head] = []\n",
    "            attributes[final_head].append(token)\n",
    "\n",
    "    return attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b82e768-eaa7-44ad-84ac-4b203a50136c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# 4. STAGE 3 ANALYSIS (UPDATED Event Extraction)\n",
    "# ==============================================================================\n",
    "def analyze_story_for_deep_context(stage2_output):\n",
    "    story_analysis = []\n",
    "    known_characters_in_story = set()\n",
    "\n",
    "    for scene in stage2_output:\n",
    "        sentence_text = scene[\"text\"]\n",
    "\n",
    "        # --- 1. Named Entities ---\n",
    "        entities, known_characters_in_story = extract_entities_solved(\n",
    "            sentence_text, known_characters_in_story\n",
    "        )\n",
    "\n",
    "        doc = nlp(sentence_text)\n",
    "\n",
    "        scene_data_for_attributes = {\n",
    "            \"tokens\": [token.text for token in doc],\n",
    "            \"dependencies\": [(token.text, token.dep_, token.head.text) for token in doc]\n",
    "        }\n",
    "        # Now, call the new, improved function\n",
    "        attributes = extract_attributes_improved(scene_data_for_attributes)\n",
    "\n",
    "\n",
    "        # --- 3. Emotions ---\n",
    "        emotions = emotion_classifier(sentence_text)\n",
    "\n",
    "        # --- 4. Events ---\n",
    "        detected_events = []\n",
    "        srl_result = srl_predictor.predict(sentence=sentence_text)\n",
    "        \n",
    "\n",
    "        \n",
    "        for verb_info in srl_result['verbs']:\n",
    "            # find lemma\n",
    "            verb_token = next((t for t in doc if t.text == verb_info['verb']), None)\n",
    "            verb_lemma = verb_token.lemma_ if verb_token else verb_info['verb'].lower()\n",
    "\n",
    "            # collect SRL args\n",
    "            tags = re.findall(r'\\[(.*?)\\]', verb_info['description'])\n",
    "            srl_args = {}\n",
    "            for tag in tags:\n",
    "                parts = tag.split(': ', 1)\n",
    "                if len(parts) == 2:\n",
    "                    srl_args[parts[0]] = parts[1]\n",
    "\n",
    "            # map to schema\n",
    "            if verb_lemma in event_mapping:\n",
    "                schema_info = event_mapping[verb_lemma]\n",
    "                event_type = schema_info['event_type']\n",
    "                role_map = schema_info['role_map']\n",
    "                custom_args = {}\n",
    "                for srl_role, text in srl_args.items():\n",
    "                    if srl_role in role_map:\n",
    "                        custom_args[role_map[srl_role]] = text\n",
    "                detected_events.append({\n",
    "                    \"event_method\": \"SRL-Schema\",\n",
    "                    \"event_type\": event_type,\n",
    "                    \"trigger\": verb_info['verb'],\n",
    "                    \"arguments\": custom_args\n",
    "                })\n",
    "            else:\n",
    "                detected_events.append({\n",
    "                    \"event_method\": \"SRL-Generic\",\n",
    "                    \"event_type\": \"Generic\",\n",
    "                    \"trigger\": verb_info['verb'],\n",
    "                    \"arguments\": srl_args\n",
    "                  })\n",
    "\n",
    "        story_analysis.append({\n",
    "            \"scene_id\": scene[\"scene_id\"],\n",
    "            \"text\": sentence_text,\n",
    "            \"entities\": entities,\n",
    "            \"attributes\": attributes,\n",
    "            \"emotions\": emotions,\n",
    "            \"events\": detected_events\n",
    "        })\n",
    "\n",
    "    return story_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de884e11-01cd-41ba-9a1f-2e7549d458a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# 5. CLEANER FOR JSON SERIALIZATION\n",
    "# ==============================================================================\n",
    "def clean_for_json(obj):\n",
    "    if isinstance(obj, dict):\n",
    "        return {k: clean_for_json(v) for k, v in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [clean_for_json(v) for v in obj]\n",
    "    elif hasattr(obj, \"item\"):\n",
    "        return obj.item()\n",
    "    else:\n",
    "        return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3dd6b67f-9fcc-4619-8626-14a9e4fd8c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"scene_id\": 1,\n",
      "    \"text\": \"Once , a hare laughed at a tortoise for being slow .\",\n",
      "    \"entities\": [\n",
      "      {\n",
      "        \"entity_group\": \"Character\",\n",
      "        \"word\": \"hare\",\n",
      "        \"score\": 1.0,\n",
      "        \"source\": \"Rule\"\n",
      "      },\n",
      "      {\n",
      "        \"entity_group\": \"Location\",\n",
      "        \"word\": \"tortoise\",\n",
      "        \"score\": 1.0,\n",
      "        \"source\": \"Rule\"\n",
      "      }\n",
      "    ],\n",
      "    \"attributes\": {\n",
      "      \"laughed\": [\n",
      "        \"Once\"\n",
      "      ],\n",
      "      \"being\": [\n",
      "        \"slow\"\n",
      "      ]\n",
      "    },\n",
      "    \"emotions\": [\n",
      "      {\n",
      "        \"label\": \"amusement\",\n",
      "        \"score\": 0.7049156427383423\n",
      "      }\n",
      "    ],\n",
      "    \"events\": [\n",
      "      {\n",
      "        \"event_method\": \"SRL-Generic\",\n",
      "        \"event_type\": \"Generic\",\n",
      "        \"trigger\": \"laughed\",\n",
      "        \"arguments\": {\n",
      "          \"ARGM-TMP\": \"Once\",\n",
      "          \"ARG0\": \"a hare\",\n",
      "          \"V\": \"laughed\",\n",
      "          \"ARG2\": \"at a tortoise\",\n",
      "          \"ARGM-CAU\": \"for being slow\"\n",
      "        }\n",
      "      },\n",
      "      {\n",
      "        \"event_method\": \"SRL-Generic\",\n",
      "        \"event_type\": \"Generic\",\n",
      "        \"trigger\": \"being\",\n",
      "        \"arguments\": {\n",
      "          \"V\": \"being\",\n",
      "          \"ARG2\": \"slow\"\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"scene_id\": 2,\n",
      "    \"text\": \"Feeling insulted , a tortoise challenged a hare to a race .\",\n",
      "    \"entities\": [\n",
      "      {\n",
      "        \"entity_group\": \"Character\",\n",
      "        \"word\": \"tortoise\",\n",
      "        \"score\": 1.0,\n",
      "        \"source\": \"Rule\"\n",
      "      },\n",
      "      {\n",
      "        \"entity_group\": \"Character\",\n",
      "        \"word\": \"hare\",\n",
      "        \"score\": 1.0,\n",
      "        \"source\": \"Rule\"\n",
      "      },\n",
      "      {\n",
      "        \"entity_group\": \"Location\",\n",
      "        \"word\": \"race\",\n",
      "        \"score\": 1.0,\n",
      "        \"source\": \"Rule\"\n",
      "      }\n",
      "    ],\n",
      "    \"attributes\": {\n",
      "      \"Feeling\": [\n",
      "        \"insulted\"\n",
      "      ]\n",
      "    },\n",
      "    \"emotions\": [\n",
      "      {\n",
      "        \"label\": \"annoyance\",\n",
      "        \"score\": 0.32556283473968506\n",
      "      }\n",
      "    ],\n",
      "    \"events\": [\n",
      "      {\n",
      "        \"event_method\": \"SRL-Generic\",\n",
      "        \"event_type\": \"Generic\",\n",
      "        \"trigger\": \"Feeling\",\n",
      "        \"arguments\": {\n",
      "          \"V\": \"Feeling\",\n",
      "          \"ARG1\": \"insulted\",\n",
      "          \"ARG0\": \"a tortoise\"\n",
      "        }\n",
      "      },\n",
      "      {\n",
      "        \"event_method\": \"SRL-Generic\",\n",
      "        \"event_type\": \"Generic\",\n",
      "        \"trigger\": \"insulted\",\n",
      "        \"arguments\": {\n",
      "          \"V\": \"insulted\",\n",
      "          \"ARG1\": \"a tortoise\"\n",
      "        }\n",
      "      },\n",
      "      {\n",
      "        \"event_method\": \"SRL-Generic\",\n",
      "        \"event_type\": \"Generic\",\n",
      "        \"trigger\": \"challenged\",\n",
      "        \"arguments\": {\n",
      "          \"R-ARG0\": \"Feeling insulted\",\n",
      "          \"ARG0\": \"a tortoise\",\n",
      "          \"V\": \"challenged\",\n",
      "          \"ARG1\": \"a hare\",\n",
      "          \"ARG2\": \"to a race\"\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"scene_id\": 3,\n",
      "    \"text\": \"At the start , a hare ran quickly and left a tortoise far behind , but a hare soon grew overconfident and decided to rest .\",\n",
      "    \"entities\": [\n",
      "      {\n",
      "        \"entity_group\": \"Location\",\n",
      "        \"word\": \"start\",\n",
      "        \"score\": 1.0,\n",
      "        \"source\": \"Rule\"\n",
      "      },\n",
      "      {\n",
      "        \"entity_group\": \"Character\",\n",
      "        \"word\": \"hare\",\n",
      "        \"score\": 1.0,\n",
      "        \"source\": \"Rule\"\n",
      "      },\n",
      "      {\n",
      "        \"entity_group\": \"Character\",\n",
      "        \"word\": \"tortoise\",\n",
      "        \"score\": 1.0,\n",
      "        \"source\": \"Rule\"\n",
      "      }\n",
      "    ],\n",
      "    \"attributes\": {\n",
      "      \"ran\": [\n",
      "        \"quickly\"\n",
      "      ],\n",
      "      \"behind\": [\n",
      "        \"far\"\n",
      "      ],\n",
      "      \"left\": [\n",
      "        \"behind\"\n",
      "      ],\n",
      "      \"grew\": [\n",
      "        \"soon\"\n",
      "      ],\n",
      "      \"hare\": [\n",
      "        \"overconfident\"\n",
      "      ],\n",
      "      \"decided\": [\n",
      "        \"rest\"\n",
      "      ]\n",
      "    },\n",
      "    \"emotions\": [\n",
      "      {\n",
      "        \"label\": \"neutral\",\n",
      "        \"score\": 0.7136326432228088\n",
      "      }\n",
      "    ],\n",
      "    \"events\": [\n",
      "      {\n",
      "        \"event_method\": \"SRL-Generic\",\n",
      "        \"event_type\": \"Generic\",\n",
      "        \"trigger\": \"ran\",\n",
      "        \"arguments\": {\n",
      "          \"ARGM-TMP\": \"At the start\",\n",
      "          \"ARG0\": \"a hare\",\n",
      "          \"V\": \"ran\",\n",
      "          \"ARGM-MNR\": \"quickly\"\n",
      "        }\n",
      "      },\n",
      "      {\n",
      "        \"event_method\": \"SRL-Generic\",\n",
      "        \"event_type\": \"Generic\",\n",
      "        \"trigger\": \"left\",\n",
      "        \"arguments\": {\n",
      "          \"ARGM-TMP\": \"At the start\",\n",
      "          \"ARG0\": \"a hare\",\n",
      "          \"V\": \"left\",\n",
      "          \"ARG1\": \"a tortoise\",\n",
      "          \"ARGM-LOC\": \"far behind\"\n",
      "        }\n",
      "      },\n",
      "      {\n",
      "        \"event_method\": \"SRL-Generic\",\n",
      "        \"event_type\": \"Generic\",\n",
      "        \"trigger\": \"grew\",\n",
      "        \"arguments\": {\n",
      "          \"ARG1\": \"a hare\",\n",
      "          \"ARGM-TMP\": \"soon\",\n",
      "          \"V\": \"grew\",\n",
      "          \"ARG2\": \"overconfident\"\n",
      "        }\n",
      "      },\n",
      "      {\n",
      "        \"event_method\": \"SRL-Generic\",\n",
      "        \"event_type\": \"Generic\",\n",
      "        \"trigger\": \"decided\",\n",
      "        \"arguments\": {\n",
      "          \"ARG0\": \"a hare\",\n",
      "          \"ARGM-TMP\": \"soon\",\n",
      "          \"V\": \"decided\",\n",
      "          \"ARG1\": \"to rest\"\n",
      "        }\n",
      "      },\n",
      "      {\n",
      "        \"event_method\": \"SRL-Generic\",\n",
      "        \"event_type\": \"Generic\",\n",
      "        \"trigger\": \"rest\",\n",
      "        \"arguments\": {\n",
      "          \"ARG1\": \"a hare\",\n",
      "          \"V\": \"rest\"\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"scene_id\": 4,\n",
      "    \"text\": \"While a hare slept , a tortoise kept moving steadily and , in the end , crossed the finish line first , winning a race .\",\n",
      "    \"entities\": [\n",
      "      {\n",
      "        \"entity_group\": \"Character\",\n",
      "        \"word\": \"hare\",\n",
      "        \"score\": 1.0,\n",
      "        \"source\": \"Rule\"\n",
      "      },\n",
      "      {\n",
      "        \"entity_group\": \"Character\",\n",
      "        \"word\": \"tortoise\",\n",
      "        \"score\": 1.0,\n",
      "        \"source\": \"Rule\"\n",
      "      },\n",
      "      {\n",
      "        \"entity_group\": \"Location\",\n",
      "        \"word\": \"end\",\n",
      "        \"score\": 1.0,\n",
      "        \"source\": \"Rule\"\n",
      "      },\n",
      "      {\n",
      "        \"entity_group\": \"Object\",\n",
      "        \"word\": \"finish line\",\n",
      "        \"score\": 1.0,\n",
      "        \"source\": \"Rule\"\n",
      "      },\n",
      "      {\n",
      "        \"entity_group\": \"Object\",\n",
      "        \"word\": \"race\",\n",
      "        \"score\": 1.0,\n",
      "        \"source\": \"Rule\"\n",
      "      }\n",
      "    ],\n",
      "    \"attributes\": {\n",
      "      \"tortoise\": [\n",
      "        \"moving\"\n",
      "      ],\n",
      "      \"moving\": [\n",
      "        \"steadily\"\n",
      "      ],\n",
      "      \"crossed\": [\n",
      "        \"first\"\n",
      "      ]\n",
      "    },\n",
      "    \"emotions\": [\n",
      "      {\n",
      "        \"label\": \"neutral\",\n",
      "        \"score\": 0.7321919798851013\n",
      "      }\n",
      "    ],\n",
      "    \"events\": [\n",
      "      {\n",
      "        \"event_method\": \"SRL-Generic\",\n",
      "        \"event_type\": \"Generic\",\n",
      "        \"trigger\": \"slept\",\n",
      "        \"arguments\": {\n",
      "          \"ARG0\": \"a hare\",\n",
      "          \"V\": \"slept\"\n",
      "        }\n",
      "      },\n",
      "      {\n",
      "        \"event_method\": \"SRL-Generic\",\n",
      "        \"event_type\": \"Generic\",\n",
      "        \"trigger\": \"kept\",\n",
      "        \"arguments\": {\n",
      "          \"ARGM-TMP\": \"While a hare slept\",\n",
      "          \"ARG0\": \"a tortoise\",\n",
      "          \"V\": \"kept\",\n",
      "          \"ARG1\": \"moving steadily\"\n",
      "        }\n",
      "      },\n",
      "      {\n",
      "        \"event_method\": \"SRL-Generic\",\n",
      "        \"event_type\": \"Generic\",\n",
      "        \"trigger\": \"moving\",\n",
      "        \"arguments\": {\n",
      "          \"ARG1\": \"a tortoise\",\n",
      "          \"V\": \"moving\",\n",
      "          \"ARGM-MNR\": \"steadily\"\n",
      "        }\n",
      "      },\n",
      "      {\n",
      "        \"event_method\": \"SRL-Generic\",\n",
      "        \"event_type\": \"Generic\",\n",
      "        \"trigger\": \"crossed\",\n",
      "        \"arguments\": {\n",
      "          \"ARGM-TMP\": \"first\",\n",
      "          \"ARG0\": \"a tortoise\",\n",
      "          \"V\": \"crossed\",\n",
      "          \"ARG1\": \"the finish line\",\n",
      "          \"ARGM-ADV\": \"winning a race\"\n",
      "        }\n",
      "      },\n",
      "      {\n",
      "        \"event_method\": \"SRL-Generic\",\n",
      "        \"event_type\": \"Generic\",\n",
      "        \"trigger\": \"winning\",\n",
      "        \"arguments\": {\n",
      "          \"ARG0\": \"a tortoise\",\n",
      "          \"V\": \"winning\",\n",
      "          \"ARG1\": \"a race\"\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# 6. RUN & PRINT (Example Usage)\n",
    "# ==============================================================================\n",
    "# stage3_ready_input = [\n",
    "#     {\"scene_id\": 1, \"text\": \"Hare was hopping through the forest.\"},\n",
    "#     {\"scene_id\": 2, \"text\": \"Hare saw a tortoise slowly walking along the path.\"},\n",
    "#     {\"scene_id\": 3, \"text\": \"Hare greeted a tortoise.\"}\n",
    "# ]\n",
    "\n",
    "deep_context = analyze_story_for_deep_context(stage3_ready_input)\n",
    "deep_context_clean = clean_for_json(deep_context)\n",
    "\n",
    "print(json.dumps(deep_context_clean, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3384119-3a87-471d-ab65-9c4bc0446652",
   "metadata": {},
   "source": [
    "# Stage 4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d26a99a1-c3bb-455c-8c4e-a4901aec9a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading spaCy model...\n",
      "Running Stage 1 pre-processing...\n",
      "Running summarization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 60, but you input_length is only 29. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=14)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Final Scene Output:\n",
      "{\n",
      "  \"original_text\": \"Hare was hopping through the forest. He saw a tortoise slowly walking along the path. he greeted him fast. he is handsome.\",\n",
      "  \"summary\": \"Hare was hopping through the forest. He saw a tortoise slowly walking along the path. He greeted him fast.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# ========== 1. IMPORTS ==========\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import spacy\n",
    "from transformers import pipeline, T5ForConditionalGeneration, T5Tokenizer\n",
    "from typing import Optional\n",
    "\n",
    "# ========== 2. STAGE 1: PRE-PROCESSING FUNCTION ==========\n",
    "def preprocess_story(text: str, nlp_model) -> dict:\n",
    "    \"\"\"Cleans text and processes it with spaCy to get sentences.\"\"\"\n",
    "    clean_text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    doc = nlp_model(clean_text)\n",
    "    return {\"sentences\": list(doc.sents)}\n",
    "\n",
    "# ========== 3. STAGE 4: SUMMARIZATION CLASS (SIMPLIFIED) ==========\n",
    "class SceneSummarizer:\n",
    "    \"\"\"\n",
    "    A class to perform abstractive summarization on scene text.\n",
    "    \"\"\"\n",
    "    def __init__(self, model_type: str = \"bart\", local_path: Optional[str] = None):\n",
    "        \"\"\"Initializes the summarizer with a local transformer model.\"\"\"\n",
    "        self.model_type = model_type\n",
    "\n",
    "        if not local_path or not os.path.exists(local_path):\n",
    "            raise FileNotFoundError(f\"❌ Local model path not found: {local_path}\")\n",
    "\n",
    "        if model_type == \"bart\":\n",
    "            self.abstractive_model = pipeline(\"summarization\", model=local_path)\n",
    "        elif model_type == \"t5\":\n",
    "            model = T5ForConditionalGeneration.from_pretrained(local_path)\n",
    "            tokenizer = T5Tokenizer.from_pretrained(local_path)\n",
    "            self.abstractive_model = (model, tokenizer)\n",
    "        else:\n",
    "            raise ValueError(\"model_type must be 'bart' or 't5'\")\n",
    "\n",
    "    def summarize(self, text: str, max_len: int = 60, min_len: int = 15) -> str:\n",
    "        \"\"\"Generates a new, abstractive summary by understanding the text.\"\"\"\n",
    "        if self.model_type == \"bart\":\n",
    "            summary = self.abstractive_model(\n",
    "                text, max_length=max_len, min_length=min_len, do_sample=False\n",
    "            )\n",
    "            return summary[0][\"summary_text\"]\n",
    "        elif self.model_type == \"t5\":\n",
    "            model, tokenizer = self.abstractive_model\n",
    "            input_text = \"summarize: \" + text\n",
    "            inputs = tokenizer.encode(\n",
    "                input_text, return_tensors=\"pt\", max_length=1024, truncation=True\n",
    "            )\n",
    "            summary_ids = model.generate(\n",
    "                inputs, max_length=max_len, min_length=min_len, length_penalty=2.0, num_beams=4\n",
    "            )\n",
    "            return tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "        return \"\"\n",
    "\n",
    "# ========== 4. MAIN PIPELINE EXECUTION ==========\n",
    "if __name__ == \"__main__\":\n",
    "    # --- Define initial text and load NLP model ---\n",
    "    story_text = \"\"\"\n",
    "    Hare was hopping through the forest.\n",
    "    He saw a tortoise slowly walking along the path.\n",
    "    he greeted him fast.\n",
    "    he is handsome.\n",
    "    \"\"\"\n",
    "    print(\"Loading spaCy model...\")\n",
    "    nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "    # --- STAGE 1: Pre-processing ---\n",
    "    print(\"Running Stage 1 pre-processing...\")\n",
    "    stage1_output = preprocess_story(story_text, nlp)\n",
    "    full_scene_text = \" \".join([sent.text for sent in stage1_output['sentences']])\n",
    "\n",
    "    # --- STAGE 4: Summarization ---\n",
    "    print(\"Running summarization...\")\n",
    "    # IMPORTANT: Update this path to your local BART model folder\n",
    "    local_bart_path = r\"C:\\Users\\__msi__\\facebook-bart-large-cnn\"\n",
    "    \n",
    "    try:\n",
    "        summarizer = SceneSummarizer(model_type=\"bart\", local_path=local_bart_path)\n",
    "        \n",
    "        # Generate the abstractive summary\n",
    "        final_summary = summarizer.summarize(full_scene_text)\n",
    "        \n",
    "        # Store the result\n",
    "        scene_output = {\n",
    "            \"original_text\": full_scene_text,\n",
    "            \"summary\": final_summary\n",
    "        }\n",
    "        \n",
    "        # Print the final, organized output\n",
    "        print(\"\\n✅ Final Scene Output:\")\n",
    "        print(json.dumps(scene_output, indent=2))\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(e)\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "409e7fe4-0f70-464d-9f50-5f63f91fd92a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"stage2_scenes\": [\n",
      "    \"b scene [Hare was hopping through the forest .]\",\n",
      "    \"i scene [Hare saw a tortoise slowly walking along the path .]\",\n",
      "    \"i scene [Hare greeted a tortoise fast .]\",\n",
      "    \"b scene [a tortoise is handsome .]\"\n",
      "  ],\n",
      "  \"stage3_details\": [\n",
      "    {\n",
      "      \"scene_id\": 1,\n",
      "      \"text\": \"Hare was hopping through the forest .\",\n",
      "      \"entities\": [\n",
      "        {\n",
      "          \"entity_group\": \"Person\",\n",
      "          \"word\": \"Hare\",\n",
      "          \"score\": 0.986299991607666,\n",
      "          \"source\": \"NER\"\n",
      "        },\n",
      "        {\n",
      "          \"entity_group\": \"Location\",\n",
      "          \"word\": \"forest\",\n",
      "          \"score\": 1.0,\n",
      "          \"source\": \"Rule\"\n",
      "        }\n",
      "      ],\n",
      "      \"attributes\": {},\n",
      "      \"emotions\": [\n",
      "        {\n",
      "          \"label\": \"neutral\",\n",
      "          \"score\": 0.9677174091339111\n",
      "        }\n",
      "      ],\n",
      "      \"events\": [\n",
      "        {\n",
      "          \"event_method\": \"SRL-Generic\",\n",
      "          \"event_type\": \"Generic\",\n",
      "          \"trigger\": \"was\",\n",
      "          \"arguments\": {\n",
      "            \"V\": \"was\"\n",
      "          }\n",
      "        },\n",
      "        {\n",
      "          \"event_method\": \"SRL-Generic\",\n",
      "          \"event_type\": \"Generic\",\n",
      "          \"trigger\": \"hopping\",\n",
      "          \"arguments\": {\n",
      "            \"ARG0\": \"Hare\",\n",
      "            \"V\": \"hopping\",\n",
      "            \"ARGM-DIR\": \"through the forest\"\n",
      "          }\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"scene_id\": 2,\n",
      "      \"text\": \"Hare saw a tortoise slowly walking along the path .\",\n",
      "      \"entities\": [\n",
      "        {\n",
      "          \"entity_group\": \"Person\",\n",
      "          \"word\": \"Hare\",\n",
      "          \"score\": 0.9977999925613403,\n",
      "          \"source\": \"NER\"\n",
      "        },\n",
      "        {\n",
      "          \"entity_group\": \"Character\",\n",
      "          \"word\": \"tortoise\",\n",
      "          \"score\": 1.0,\n",
      "          \"source\": \"Rule\"\n",
      "        },\n",
      "        {\n",
      "          \"entity_group\": \"Location\",\n",
      "          \"word\": \"path\",\n",
      "          \"score\": 1.0,\n",
      "          \"source\": \"Rule\"\n",
      "        }\n",
      "      ],\n",
      "      \"attributes\": {\n",
      "        \"walking\": [\n",
      "          \"slowly\"\n",
      "        ]\n",
      "      },\n",
      "      \"emotions\": [\n",
      "        {\n",
      "          \"label\": \"neutral\",\n",
      "          \"score\": 0.9678376317024231\n",
      "        }\n",
      "      ],\n",
      "      \"events\": [\n",
      "        {\n",
      "          \"event_method\": \"SRL-Generic\",\n",
      "          \"event_type\": \"Generic\",\n",
      "          \"trigger\": \"saw\",\n",
      "          \"arguments\": {\n",
      "            \"ARG0\": \"Hare\",\n",
      "            \"V\": \"saw\",\n",
      "            \"ARG1\": \"a tortoise slowly walking along the path\"\n",
      "          }\n",
      "        },\n",
      "        {\n",
      "          \"event_method\": \"SRL-Generic\",\n",
      "          \"event_type\": \"Generic\",\n",
      "          \"trigger\": \"walking\",\n",
      "          \"arguments\": {\n",
      "            \"ARG0\": \"a tortoise\",\n",
      "            \"ARGM-MNR\": \"slowly\",\n",
      "            \"V\": \"walking\",\n",
      "            \"ARG1\": \"along the path\"\n",
      "          }\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"scene_id\": 3,\n",
      "      \"text\": \"Hare greeted a tortoise fast .\",\n",
      "      \"entities\": [\n",
      "        {\n",
      "          \"entity_group\": \"Person\",\n",
      "          \"word\": \"Hare\",\n",
      "          \"score\": 0.9909999966621399,\n",
      "          \"source\": \"NER\"\n",
      "        },\n",
      "        {\n",
      "          \"entity_group\": \"Character\",\n",
      "          \"word\": \"tortoise\",\n",
      "          \"score\": 1.0,\n",
      "          \"source\": \"Rule\"\n",
      "        }\n",
      "      ],\n",
      "      \"attributes\": {\n",
      "        \"greeted\": [\n",
      "          \"fast\"\n",
      "        ]\n",
      "      },\n",
      "      \"emotions\": [\n",
      "        {\n",
      "          \"label\": \"neutral\",\n",
      "          \"score\": 0.9602752327919006\n",
      "        }\n",
      "      ],\n",
      "      \"events\": [\n",
      "        {\n",
      "          \"event_method\": \"SRL-Generic\",\n",
      "          \"event_type\": \"Generic\",\n",
      "          \"trigger\": \"greeted\",\n",
      "          \"arguments\": {\n",
      "            \"ARG0\": \"Hare\",\n",
      "            \"V\": \"greeted\",\n",
      "            \"ARG1\": \"a tortoise\",\n",
      "            \"ARGM-MNR\": \"fast\"\n",
      "          }\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"scene_id\": 4,\n",
      "      \"text\": \"a tortoise is handsome .\",\n",
      "      \"entities\": [\n",
      "        {\n",
      "          \"entity_group\": \"Character\",\n",
      "          \"word\": \"tortoise\",\n",
      "          \"score\": 1.0,\n",
      "          \"source\": \"Rule\"\n",
      "        }\n",
      "      ],\n",
      "      \"attributes\": {\n",
      "        \"tortoise\": [\n",
      "          \"handsome\"\n",
      "        ]\n",
      "      },\n",
      "      \"emotions\": [\n",
      "        {\n",
      "          \"label\": \"admiration\",\n",
      "          \"score\": 0.9384015798568726\n",
      "        }\n",
      "      ],\n",
      "      \"events\": [\n",
      "        {\n",
      "          \"event_method\": \"SRL-Generic\",\n",
      "          \"event_type\": \"Generic\",\n",
      "          \"trigger\": \"is\",\n",
      "          \"arguments\": {\n",
      "            \"ARG1\": \"a tortoise\",\n",
      "            \"V\": \"is\",\n",
      "            \"ARG2\": \"handsome\"\n",
      "          }\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"summary_output\": {\n",
      "    \"original_text\": \"Hare was hopping through the forest. He saw a tortoise slowly walking along the path. he greeted him fast. he is handsome.\",\n",
      "    \"summary\": \"Hare was hopping through the forest. He saw a tortoise slowly walking along the path. He greeted him fast.\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "def build_final_structure(stage2_output, deep_context_clean, scene_output):\n",
    "    \"\"\"\n",
    "    Combines Stage 2, Stage 3, and Stage 4 outputs into the final structure\n",
    "    ready for Knowledge Graph construction.\n",
    "    \n",
    "    Parameters:\n",
    "        stage2_output (list): Output list from Stage 2 (scene annotations).\n",
    "        deep_context_clean (list): Output list from Stage 3 (deep analysis).\n",
    "        scene_output (dict): Output dict from Stage 4 (original text + summary).\n",
    "    \n",
    "    Returns:\n",
    "        dict: Final structured JSON-like dictionary.\n",
    "    \"\"\"\n",
    "    final_structure = {\n",
    "        \"stage2_scenes\": stage2_output,\n",
    "        \"stage3_details\": deep_context_clean,\n",
    "        \"summary_output\": scene_output\n",
    "    }\n",
    "    return final_structure\n",
    "\n",
    "\n",
    "#============================\n",
    "#Example Usage\n",
    "#============================\n",
    "final_data = build_final_structure(stage2_output, deep_context_clean, scene_output)\n",
    "print(json.dumps(final_data, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b79f8614-b8d0-4130-b701-c2a98cfe2b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes\n"
     ]
    }
   ],
   "source": [
    "# robust_kg_loader.py\n",
    "import re\n",
    "import json\n",
    "import logging\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "from neo4j import GraphDatabase, Transaction, basic_auth\n",
    "\n",
    "# ---------------------------\n",
    "# Logging setup (adjustable)\n",
    "# ---------------------------\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(\"RobustKG\")\n",
    "\n",
    "# ---------------------------\n",
    "# Helper functions\n",
    "# ---------------------------\n",
    "def normalize_text(s: str) -> str:\n",
    "    \"\"\"Normalize a string for matching: lowercase, trim, remove extra punctuation, collapse spaces.\"\"\"\n",
    "    if s is None:\n",
    "        return \"\"\n",
    "    s = re.sub(r\"[“”\\\"'`]\", \"\", s)\n",
    "    s = re.sub(r'\\s+', ' ', s)\n",
    "    s = s.strip().lower()\n",
    "    return s\n",
    "\n",
    "def tokens_of(text: str) -> List[str]:\n",
    "    \"\"\"Simple tokenization (split by whitespace) for matching purposes.\"\"\"\n",
    "    return [t for t in re.split(r'\\W+', text) if t]\n",
    "\n",
    "def best_match_entity_name(target_text: str, candidate_names: List[str]) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Try to map a piece of argument text back to an existing canonical entity name.\n",
    "    Strategies (in order):\n",
    "      1) exact normalized match\n",
    "      2) token-subset match (all tokens of candidate appear in target_text)\n",
    "      3) token overlap max\n",
    "    Returns the canonical candidate name (not normalized) or None.\n",
    "    \"\"\"\n",
    "    if not target_text or not candidate_names:\n",
    "        return None\n",
    "    n_target = normalize_text(target_text)\n",
    "\n",
    "    # Precompute normalized candidate map: normalized -> original\n",
    "    norm_to_orig = {}\n",
    "    for c in candidate_names:\n",
    "        norm = normalize_text(c)\n",
    "        if norm:\n",
    "            norm_to_orig.setdefault(norm, c)\n",
    "\n",
    "    # 1) exact normalized\n",
    "    if n_target in norm_to_orig:\n",
    "        return norm_to_orig[n_target]\n",
    "\n",
    "    # 2) if candidate tokens are subset of target tokens\n",
    "    target_tokens = set(tokens_of(n_target))\n",
    "    if not target_tokens:\n",
    "        return None\n",
    "\n",
    "    best_candidate = None\n",
    "    best_overlap = 0\n",
    "    for orig in candidate_names:\n",
    "        cand_norm = normalize_text(orig)\n",
    "        cand_tokens = set(tokens_of(cand_norm))\n",
    "        if not cand_tokens:\n",
    "            continue\n",
    "        if cand_tokens.issubset(target_tokens):\n",
    "            return orig  # strong signal\n",
    "        # compute overlap for fallback\n",
    "        overlap = len(cand_tokens & target_tokens)\n",
    "        if overlap > best_overlap:\n",
    "            best_overlap = overlap\n",
    "            best_candidate = orig\n",
    "\n",
    "    # Require at least one token overlap to consider (avoid wrong matches)\n",
    "    if best_overlap >= 1:\n",
    "        return best_candidate\n",
    "\n",
    "    return None\n",
    "\n",
    "# ---------------------------\n",
    "# Robust KG Loader Class\n",
    "# ---------------------------\n",
    "class RobustKnowledgeGraphLoader:\n",
    "    def __init__(self, uri: str, user: str, password: str, encryption=False):\n",
    "        \"\"\"\n",
    "        Robust KG loader for Neo4j.\n",
    "          - uri: bolt URI (bolt://host:7687)\n",
    "          - user, password: credentials\n",
    "        \"\"\"\n",
    "        auth = basic_auth(user, password)\n",
    "        self.driver = GraphDatabase.driver(uri, auth=auth)\n",
    "        logger.info(\"Initialized KG loader for %s\", uri)\n",
    "\n",
    "    def close(self):\n",
    "        self.driver.close()\n",
    "        logger.info(\"Driver closed.\")\n",
    "\n",
    "    # ---- Setup: indexes and constraints (idempotent) ----\n",
    "    def ensure_schema(self):\n",
    "        \"\"\"\n",
    "        Create helpful constraints/indexes to speed up lookups and ensure uniqueness.\n",
    "        This function is idempotent -- safe to call repeatedly.\n",
    "        \"\"\"\n",
    "        constraints = [\n",
    "            \"CREATE CONSTRAINT IF NOT EXISTS FOR (s:Story) REQUIRE s.story_id IS UNIQUE\",\n",
    "            \"CREATE CONSTRAINT IF NOT EXISTS FOR (e:Entity) REQUIRE (e.entity_id) IS UNIQUE\",\n",
    "            \"CREATE CONSTRAINT IF NOT EXISTS FOR (sc:Scene) REQUIRE (sc.scene_uid) IS UNIQUE\",\n",
    "            \"CREATE CONSTRAINT IF NOT EXISTS FOR (ev:Event) REQUIRE (ev.event_id) IS UNIQUE\",\n",
    "        ]\n",
    "        with self.driver.session() as session:\n",
    "            for c in constraints:\n",
    "                logger.debug(\"Running constraint/index: %s\", c)\n",
    "                session.run(c)\n",
    "        logger.info(\"Schema constraints ensured.\")\n",
    "\n",
    "    # ---- Utility to generate safe unique ids ----\n",
    "    @staticmethod\n",
    "    def _make_story_id(story_title: str) -> str:\n",
    "        return normalize_text(story_title).replace(\" \", \"_\")[:200]\n",
    "\n",
    "    @staticmethod\n",
    "    def _make_entity_id(story_id: str, name: str) -> str:\n",
    "        return f\"{story_id}::entity::{normalize_text(name)}\"\n",
    "\n",
    "    @staticmethod\n",
    "    def _make_scene_uid(story_id: str, scene_id: int) -> str:\n",
    "        return f\"{story_id}::scene::{scene_id}\"\n",
    "\n",
    "    @staticmethod\n",
    "    def _make_event_id(story_id: str, scene_id: int, idx: int) -> str:\n",
    "        return f\"{story_id}::event::{scene_id}::{idx}\"\n",
    "\n",
    "    # ---- Clear only a story (safe) ----\n",
    "    def clear_story(self, story_id: str):\n",
    "        \"\"\"Safely delete nodes and relationships for a single story_id.\"\"\"\n",
    "        q = \"\"\"\n",
    "        MATCH (s:Story {story_id: $story_id})-[r0*0..]->()\n",
    "        WITH s\n",
    "        OPTIONAL MATCH (s)-[:HAS_SCENE]->(sc:Scene)\n",
    "        OPTIONAL MATCH (sc)-[r]-()\n",
    "        DETACH DELETE s, sc\n",
    "        \"\"\"\n",
    "        with self.driver.session() as session:\n",
    "            session.run(q, story_id=story_id)\n",
    "        logger.info(\"Cleared story and its scenes for story_id=%s\", story_id)\n",
    "\n",
    "    # ---- Core loader ----\n",
    "    def load_pipeline_output(self, pipeline_output: Dict, story_title: str = \"Fable\", clear_story_first: bool = False, dry_run: bool = False) -> Dict:\n",
    "        \"\"\"\n",
    "        Main entrypoint to load pipeline_output into KG.\n",
    "        - pipeline_output: the dict you produced (stage2_scenes, stage3_details, summary_output)\n",
    "        - story_title: name for the story (used for scoping)\n",
    "        - clear_story_first: if True, remove previous nodes for this story_id\n",
    "        - dry_run: if True, do not write anything, only return what WOULD be done\n",
    "        Returns a report dict with counts and any mapping issues.\n",
    "        \"\"\"\n",
    "        report = {\n",
    "            \"created_entities\": 0,\n",
    "            \"created_scenes\": 0,\n",
    "            \"created_events\": 0,\n",
    "            \"created_attributes\": 0,\n",
    "            \"created_emotions\": 0,\n",
    "            \"warnings\": []\n",
    "        }\n",
    "\n",
    "        self.ensure_schema()\n",
    "        story_id = self._make_story_id(story_title)\n",
    "\n",
    "        if clear_story_first:\n",
    "            if dry_run:\n",
    "                logger.info(\"[dry_run] Would clear story: %s\", story_id)\n",
    "            else:\n",
    "                self.clear_story(story_id)\n",
    "\n",
    "        # prepare canonical entity set as we load scenes to allow good matching\n",
    "        canonical_entities = {}  # normalized -> canonical name\n",
    "\n",
    "        if dry_run:\n",
    "            logger.info(\"[dry_run] Starting dry-run; no changes will be committed\")\n",
    "\n",
    "        # We'll process scenes in order present in stage3_details (safe assumption)\n",
    "        scenes = pipeline_output.get(\"stage3_details\", [])\n",
    "        stage2_scenes = pipeline_output.get(\"stage2_scenes\", [])\n",
    "\n",
    "        # Create Story node (MERGE)\n",
    "        story_summary = pipeline_output.get(\"summary_output\", {}).get(\"summary\", \"\")\n",
    "        story_original_text = pipeline_output.get(\"summary_output\", {}).get(\"original_text\", \"\")\n",
    "\n",
    "        if not dry_run:\n",
    "            with self.driver.session() as session:\n",
    "                session.run(\n",
    "                    \"MERGE (st:Story {story_id: $story_id}) \"\n",
    "                    \"SET st.title = $title, st.summary = $summary, st.original_text = $original_text\",\n",
    "                    story_id=story_id, title=story_title, summary=story_summary, original_text=story_original_text\n",
    "                )\n",
    "        else:\n",
    "            logger.info(\"[dry_run] Would MERGE Story with id=%s\", story_id)\n",
    "\n",
    "        # Pre-scan entities across all scenes to build initial canonical list (helps mapping)\n",
    "        for s in scenes:\n",
    "            for ent in s.get(\"entities\", []):\n",
    "                name = ent.get(\"word\") or ent.get(\"text\") or \"\"\n",
    "                if not name:\n",
    "                    continue\n",
    "                norm = normalize_text(name)\n",
    "                if norm and norm not in canonical_entities:\n",
    "                    canonical_entities[norm] = name\n",
    "\n",
    "        # Helper to ensure entity node exists and return canonical name\n",
    "        def ensure_entity(session: Transaction, entity_name: str):\n",
    "            if not entity_name:\n",
    "                return None\n",
    "            canonical = canonical_entities.get(normalize_text(entity_name), entity_name)\n",
    "            entity_id = self._make_entity_id(story_id, canonical)\n",
    "            # create/merge entity node with some metadata\n",
    "            q = \"\"\"\n",
    "            MERGE (e:Entity {entity_id: $entity_id})\n",
    "            ON CREATE SET e.name = $name, e.type = $etype, e.first_seen = timestamp()\n",
    "            SET e.last_seen = timestamp()\n",
    "            RETURN e.entity_id AS entity_id, e.name AS name\n",
    "            \"\"\"\n",
    "            params = {\"entity_id\": entity_id, \"name\": canonical, \"etype\": \"Unknown\"}\n",
    "            result = session.run(q, **params)\n",
    "            _ = result.single()\n",
    "            return canonical\n",
    "\n",
    "        # Now iterate scenes and load them\n",
    "        with self.driver.session() as session:\n",
    "            for idx, scene in enumerate(scenes):\n",
    "                scene_id = scene.get(\"scene_id\", idx + 1)\n",
    "                scene_text = scene.get(\"text\", \"\")\n",
    "                # scene_str (b/i) might exist in stage2_scenes at same index; fallback to 'unknown'\n",
    "                scene_str = stage2_scenes[idx] if idx < len(stage2_scenes) else \"unknown scene\"\n",
    "                # classify type robustly\n",
    "                stype = \"unknown\"\n",
    "                stype_raw = scene_str.strip().lower()\n",
    "                if stype_raw.startswith(\"b scene\"):\n",
    "                    stype = \"beginning\"\n",
    "                elif stype_raw.startswith(\"i scene\"):\n",
    "                    stype = \"intermediate\"\n",
    "                elif stype_raw.startswith(\"e scene\"):\n",
    "                    stype = \"ending\"\n",
    "                else:\n",
    "                    # maybe it contains markers in other forms\n",
    "                    if \"begin\" in stype_raw or \"b_scene\" in stype_raw:\n",
    "                        stype = \"beginning\"\n",
    "                    elif \"inter\" in stype_raw:\n",
    "                        stype = \"intermediate\"\n",
    "\n",
    "                scene_uid = self._make_scene_uid(story_id, scene_id)\n",
    "                if dry_run:\n",
    "                    logger.info(\"[dry_run] Would create Scene id=%s type=%s text=%s\", scene_uid, stype, scene_text)\n",
    "                    report[\"created_scenes\"] += 1\n",
    "                else:\n",
    "                    # create Scene node and link to story\n",
    "                    session.run(\n",
    "                        \"MATCH (st:Story {story_id: $story_id}) \"\n",
    "                        \"MERGE (sc:Scene {scene_uid: $scene_uid}) \"\n",
    "                        \"SET sc.scene_id = $scene_id, sc.scene_uid = $scene_uid, sc.type = $stype, sc.text = $text, sc.created = timestamp() \"\n",
    "                        \"MERGE (st)-[:HAS_SCENE {order: $order}]->(sc)\",\n",
    "                        story_id=story_id, scene_uid=scene_uid, scene_id=scene_id, stype=stype, text=scene_text, order=idx\n",
    "                    )\n",
    "                    report[\"created_scenes\"] += 1\n",
    "\n",
    "                # Create or ensure Entities for this scene\n",
    "                scene_entity_names = []\n",
    "                for ent in scene.get(\"entities\", []):\n",
    "                    ent_name = ent.get(\"word\") or ent.get(\"name\") or \"\"\n",
    "                    if not ent_name:\n",
    "                        continue\n",
    "                    # Update canonical list if new\n",
    "                    norm = normalize_text(ent_name)\n",
    "                    if norm not in canonical_entities:\n",
    "                        canonical_entities[norm] = ent_name\n",
    "                    # ensure node\n",
    "                    canonical = ensure_entity(session, ent_name)\n",
    "                    scene_entity_names.append(canonical)\n",
    "                    report[\"created_entities\"] += 1\n",
    "\n",
    "                # Map events and create Event nodes\n",
    "                for ev_idx, event in enumerate(scene.get(\"events\", [])):\n",
    "                    ev_id = self._make_event_id(story_id, scene_id, ev_idx)\n",
    "                    trigger = event.get(\"trigger\") or event.get(\"verb\") or \"unknown\"\n",
    "                    arguments = event.get(\"arguments\", {}) or {}\n",
    "\n",
    "                    # create Event node and link it to scene\n",
    "                    if dry_run:\n",
    "                        logger.info(\"[dry_run] Would create Event %s trigger=%s\", ev_id, trigger)\n",
    "                        report[\"created_events\"] += 1\n",
    "                    else:\n",
    "                        session.run(\n",
    "                            \"MATCH (sc:Scene {scene_uid: $scene_uid}) \"\n",
    "                            \"MERGE (ev:Event {event_id: $event_id}) \"\n",
    "                            \"SET ev.trigger = $trigger, ev.method = $method, ev.event_type = $etype, ev.created = timestamp() \"\n",
    "                            \"MERGE (sc)-[:CONTAINS_EVENT]->(ev)\",\n",
    "                            scene_uid=scene_uid, event_id=ev_id, trigger=trigger,\n",
    "                            method=event.get(\"event_method\", \"unknown\"),\n",
    "                            etype=event.get(\"event_type\", \"Generic\")\n",
    "                        )\n",
    "                        report[\"created_events\"] += 1\n",
    "\n",
    "                    # Create relationships from entities to event (map argument text to entities)\n",
    "                    for role, arg_text in arguments.items():\n",
    "                        if not arg_text:\n",
    "                            continue\n",
    "                        # try to map arg_text to an existing entity canonical name\n",
    "                        candidate_names = list(canonical_entities.values())\n",
    "                        mapped = best_match_entity_name(arg_text, candidate_names)\n",
    "                        # If best match fails, fall back to exact substring search in scene_entity_names\n",
    "                        if not mapped:\n",
    "                            for cand in scene_entity_names:\n",
    "                                if normalize_text(cand) in normalize_text(arg_text):\n",
    "                                    mapped = cand\n",
    "                                    break\n",
    "\n",
    "                        # If still not found, we create a scene-scoped entity (this avoids global conflicts)\n",
    "                        if not mapped:\n",
    "                            # fallback name is cleaned arg_text\n",
    "                            fallback_name = arg_text.strip()\n",
    "                            # create a new canonical key\n",
    "                            canonical_entities[normalize_text(fallback_name)] = fallback_name\n",
    "                            if dry_run:\n",
    "                                logger.info(\"[dry_run] Would create fallback Entity for arg_text=%s\", arg_text)\n",
    "                                mapped = fallback_name\n",
    "                                report[\"created_entities\"] += 1\n",
    "                            else:\n",
    "                                canonical = ensure_entity(session, fallback_name)\n",
    "                                mapped = canonical\n",
    "                                report[\"created_entities\"] += 1\n",
    "\n",
    "                        # Now link entity to event with role property\n",
    "                        if dry_run:\n",
    "                            logger.info(\"[dry_run] Would link Entity(%s) -> PARTICIPATED_IN(role=%s) -> Event(%s)\", mapped, role, ev_id)\n",
    "                        else:\n",
    "                            # match entity by its entity_id (scoped) and link\n",
    "                            entity_id = self._make_entity_id(story_id, mapped)\n",
    "                            session.run(\n",
    "                                \"MATCH (ev:Event {event_id: $event_id}), (e:Entity {entity_id: $entity_id}) \"\n",
    "                                \"MERGE (e)-[r:PARTICIPATED_IN {role: $role}]->(ev) \"\n",
    "                                \"SET r.role = $role\",\n",
    "                                event_id=ev_id, entity_id=entity_id, role=role\n",
    "                            )\n",
    "\n",
    "                # Attributes: attach to entity, optionally scene-scoped property\n",
    "                for target, attrs in scene.get(\"attributes\", {}).items():\n",
    "                    if not attrs:\n",
    "                        continue\n",
    "                    # map target to canonical entity\n",
    "                    mapped_target = best_match_entity_name(target, list(canonical_entities.values()))\n",
    "                    if not mapped_target:\n",
    "                        mapped_target = target\n",
    "                        # create entity if missing\n",
    "                        if not dry_run:\n",
    "                            ensure_entity(session, mapped_target)\n",
    "                            report[\"created_entities\"] += 1\n",
    "                    for attr in attrs:\n",
    "                        if dry_run:\n",
    "                            logger.info(\"[dry_run] Would attach Attribute(%s) to Entity(%s) in Scene(%s)\", attr, mapped_target, scene_uid)\n",
    "                            report[\"created_attributes\"] += 1\n",
    "                        else:\n",
    "                            entity_id = self._make_entity_id(story_id, mapped_target)\n",
    "                            session.run(\n",
    "                                \"MERGE (a:Attribute {name: $attr_name, story_id: $story_id}) \"\n",
    "                                \"MERGE (e:Entity {entity_id: $entity_id}) \"\n",
    "                                \"MERGE (e)-[:HAS_ATTRIBUTE]->(a) \"\n",
    "                                \"ON CREATE SET a.created = timestamp()\",\n",
    "                                attr_name=attr, story_id=story_id, entity_id=entity_id\n",
    "                            )\n",
    "                            report[\"created_attributes\"] += 1\n",
    "\n",
    "                # Emotions: attach emotion nodes and relation to scene (with score)\n",
    "                for emo in scene.get(\"emotions\", []):\n",
    "                    label = emo.get(\"label\")\n",
    "                    score = float(emo.get(\"score\", 0.0))\n",
    "                    if dry_run:\n",
    "                        logger.info(\"[dry_run] Would create Emotion(%s) and link to Scene(%s) score=%s\", label, scene_uid, score)\n",
    "                        report[\"created_emotions\"] += 1\n",
    "                    else:\n",
    "                        session.run(\n",
    "                            \"MERGE (em:Emotion {label: $label, story_id: $story_id}) \"\n",
    "                            \"WITH em \"\n",
    "                            \"MATCH (sc:Scene {scene_uid: $scene_uid}) \"\n",
    "                            \"MERGE (sc)-[r:HAS_EMOTION]->(em) \"\n",
    "                            \"SET r.score = $score\",\n",
    "                            label=label, story_id=story_id, scene_uid=scene_uid, score=score\n",
    "                        )\n",
    "                        report[\"created_emotions\"] += 1\n",
    "\n",
    "        logger.info(\"KG load complete. report=%s\", report)\n",
    "        return report\n",
    "print(\"Yes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c438be4a-ff3e-475e-a795-7116866365db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:RobustKG:Initialized KG loader for neo4j://127.0.0.1:7687\n",
      "INFO:RobustKG:Schema constraints ensured.\n",
      "INFO:RobustKG:Cleared story and its scenes for story_id=fable\n",
      "INFO:neo4j.notifications:Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Statement.CartesianProduct} {category: PERFORMANCE} {title: This query builds a cartesian product between disconnected patterns.} {description: If a part of a query contains multiple disconnected patterns, this will build a cartesian product between all those parts. This may produce a large amount of data and slow down query processing. While occasionally intended, it may often be possible to reformulate the query that avoids the use of this cross product, perhaps by adding a relationship between the different parts or by using OPTIONAL MATCH (identifier is: (e))} {position: line: 1, column: 1, offset: 0} for query: 'MATCH (ev:Event {event_id: $event_id}), (e:Entity {entity_id: $entity_id}) MERGE (e)-[r:PARTICIPATED_IN {role: $role}]->(ev) SET r.role = $role'\n",
      "INFO:neo4j.notifications:Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Statement.CartesianProduct} {category: PERFORMANCE} {title: This query builds a cartesian product between disconnected patterns.} {description: If a part of a query contains multiple disconnected patterns, this will build a cartesian product between all those parts. This may produce a large amount of data and slow down query processing. While occasionally intended, it may often be possible to reformulate the query that avoids the use of this cross product, perhaps by adding a relationship between the different parts or by using OPTIONAL MATCH (identifier is: (e))} {position: line: 1, column: 1, offset: 0} for query: 'MATCH (ev:Event {event_id: $event_id}), (e:Entity {entity_id: $entity_id}) MERGE (e)-[r:PARTICIPATED_IN {role: $role}]->(ev) SET r.role = $role'\n",
      "INFO:neo4j.notifications:Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Statement.CartesianProduct} {category: PERFORMANCE} {title: This query builds a cartesian product between disconnected patterns.} {description: If a part of a query contains multiple disconnected patterns, this will build a cartesian product between all those parts. This may produce a large amount of data and slow down query processing. While occasionally intended, it may often be possible to reformulate the query that avoids the use of this cross product, perhaps by adding a relationship between the different parts or by using OPTIONAL MATCH (identifier is: (e))} {position: line: 1, column: 1, offset: 0} for query: 'MATCH (ev:Event {event_id: $event_id}), (e:Entity {entity_id: $entity_id}) MERGE (e)-[r:PARTICIPATED_IN {role: $role}]->(ev) SET r.role = $role'\n",
      "INFO:neo4j.notifications:Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Statement.CartesianProduct} {category: PERFORMANCE} {title: This query builds a cartesian product between disconnected patterns.} {description: If a part of a query contains multiple disconnected patterns, this will build a cartesian product between all those parts. This may produce a large amount of data and slow down query processing. While occasionally intended, it may often be possible to reformulate the query that avoids the use of this cross product, perhaps by adding a relationship between the different parts or by using OPTIONAL MATCH (identifier is: (e))} {position: line: 1, column: 1, offset: 0} for query: 'MATCH (ev:Event {event_id: $event_id}), (e:Entity {entity_id: $entity_id}) MERGE (e)-[r:PARTICIPATED_IN {role: $role}]->(ev) SET r.role = $role'\n",
      "INFO:neo4j.notifications:Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Statement.CartesianProduct} {category: PERFORMANCE} {title: This query builds a cartesian product between disconnected patterns.} {description: If a part of a query contains multiple disconnected patterns, this will build a cartesian product between all those parts. This may produce a large amount of data and slow down query processing. While occasionally intended, it may often be possible to reformulate the query that avoids the use of this cross product, perhaps by adding a relationship between the different parts or by using OPTIONAL MATCH (identifier is: (e))} {position: line: 1, column: 1, offset: 0} for query: 'MATCH (ev:Event {event_id: $event_id}), (e:Entity {entity_id: $entity_id}) MERGE (e)-[r:PARTICIPATED_IN {role: $role}]->(ev) SET r.role = $role'\n",
      "INFO:neo4j.notifications:Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Statement.CartesianProduct} {category: PERFORMANCE} {title: This query builds a cartesian product between disconnected patterns.} {description: If a part of a query contains multiple disconnected patterns, this will build a cartesian product between all those parts. This may produce a large amount of data and slow down query processing. While occasionally intended, it may often be possible to reformulate the query that avoids the use of this cross product, perhaps by adding a relationship between the different parts or by using OPTIONAL MATCH (identifier is: (e))} {position: line: 1, column: 1, offset: 0} for query: 'MATCH (ev:Event {event_id: $event_id}), (e:Entity {entity_id: $entity_id}) MERGE (e)-[r:PARTICIPATED_IN {role: $role}]->(ev) SET r.role = $role'\n",
      "INFO:neo4j.notifications:Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Statement.CartesianProduct} {category: PERFORMANCE} {title: This query builds a cartesian product between disconnected patterns.} {description: If a part of a query contains multiple disconnected patterns, this will build a cartesian product between all those parts. This may produce a large amount of data and slow down query processing. While occasionally intended, it may often be possible to reformulate the query that avoids the use of this cross product, perhaps by adding a relationship between the different parts or by using OPTIONAL MATCH (identifier is: (e))} {position: line: 1, column: 1, offset: 0} for query: 'MATCH (ev:Event {event_id: $event_id}), (e:Entity {entity_id: $entity_id}) MERGE (e)-[r:PARTICIPATED_IN {role: $role}]->(ev) SET r.role = $role'\n",
      "INFO:neo4j.notifications:Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Statement.CartesianProduct} {category: PERFORMANCE} {title: This query builds a cartesian product between disconnected patterns.} {description: If a part of a query contains multiple disconnected patterns, this will build a cartesian product between all those parts. This may produce a large amount of data and slow down query processing. While occasionally intended, it may often be possible to reformulate the query that avoids the use of this cross product, perhaps by adding a relationship between the different parts or by using OPTIONAL MATCH (identifier is: (e))} {position: line: 1, column: 1, offset: 0} for query: 'MATCH (ev:Event {event_id: $event_id}), (e:Entity {entity_id: $entity_id}) MERGE (e)-[r:PARTICIPATED_IN {role: $role}]->(ev) SET r.role = $role'\n",
      "INFO:neo4j.notifications:Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Statement.CartesianProduct} {category: PERFORMANCE} {title: This query builds a cartesian product between disconnected patterns.} {description: If a part of a query contains multiple disconnected patterns, this will build a cartesian product between all those parts. This may produce a large amount of data and slow down query processing. While occasionally intended, it may often be possible to reformulate the query that avoids the use of this cross product, perhaps by adding a relationship between the different parts or by using OPTIONAL MATCH (identifier is: (e))} {position: line: 1, column: 1, offset: 0} for query: 'MATCH (ev:Event {event_id: $event_id}), (e:Entity {entity_id: $entity_id}) MERGE (e)-[r:PARTICIPATED_IN {role: $role}]->(ev) SET r.role = $role'\n",
      "INFO:neo4j.notifications:Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Statement.CartesianProduct} {category: PERFORMANCE} {title: This query builds a cartesian product between disconnected patterns.} {description: If a part of a query contains multiple disconnected patterns, this will build a cartesian product between all those parts. This may produce a large amount of data and slow down query processing. While occasionally intended, it may often be possible to reformulate the query that avoids the use of this cross product, perhaps by adding a relationship between the different parts or by using OPTIONAL MATCH (identifier is: (e))} {position: line: 1, column: 1, offset: 0} for query: 'MATCH (ev:Event {event_id: $event_id}), (e:Entity {entity_id: $entity_id}) MERGE (e)-[r:PARTICIPATED_IN {role: $role}]->(ev) SET r.role = $role'\n",
      "INFO:neo4j.notifications:Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Statement.CartesianProduct} {category: PERFORMANCE} {title: This query builds a cartesian product between disconnected patterns.} {description: If a part of a query contains multiple disconnected patterns, this will build a cartesian product between all those parts. This may produce a large amount of data and slow down query processing. While occasionally intended, it may often be possible to reformulate the query that avoids the use of this cross product, perhaps by adding a relationship between the different parts or by using OPTIONAL MATCH (identifier is: (e))} {position: line: 1, column: 1, offset: 0} for query: 'MATCH (ev:Event {event_id: $event_id}), (e:Entity {entity_id: $entity_id}) MERGE (e)-[r:PARTICIPATED_IN {role: $role}]->(ev) SET r.role = $role'\n",
      "INFO:neo4j.notifications:Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Statement.CartesianProduct} {category: PERFORMANCE} {title: This query builds a cartesian product between disconnected patterns.} {description: If a part of a query contains multiple disconnected patterns, this will build a cartesian product between all those parts. This may produce a large amount of data and slow down query processing. While occasionally intended, it may often be possible to reformulate the query that avoids the use of this cross product, perhaps by adding a relationship between the different parts or by using OPTIONAL MATCH (identifier is: (e))} {position: line: 1, column: 1, offset: 0} for query: 'MATCH (ev:Event {event_id: $event_id}), (e:Entity {entity_id: $entity_id}) MERGE (e)-[r:PARTICIPATED_IN {role: $role}]->(ev) SET r.role = $role'\n",
      "INFO:neo4j.notifications:Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Statement.CartesianProduct} {category: PERFORMANCE} {title: This query builds a cartesian product between disconnected patterns.} {description: If a part of a query contains multiple disconnected patterns, this will build a cartesian product between all those parts. This may produce a large amount of data and slow down query processing. While occasionally intended, it may often be possible to reformulate the query that avoids the use of this cross product, perhaps by adding a relationship between the different parts or by using OPTIONAL MATCH (identifier is: (e))} {position: line: 1, column: 1, offset: 0} for query: 'MATCH (ev:Event {event_id: $event_id}), (e:Entity {entity_id: $entity_id}) MERGE (e)-[r:PARTICIPATED_IN {role: $role}]->(ev) SET r.role = $role'\n",
      "INFO:neo4j.notifications:Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Statement.CartesianProduct} {category: PERFORMANCE} {title: This query builds a cartesian product between disconnected patterns.} {description: If a part of a query contains multiple disconnected patterns, this will build a cartesian product between all those parts. This may produce a large amount of data and slow down query processing. While occasionally intended, it may often be possible to reformulate the query that avoids the use of this cross product, perhaps by adding a relationship between the different parts or by using OPTIONAL MATCH (identifier is: (e))} {position: line: 1, column: 1, offset: 0} for query: 'MATCH (ev:Event {event_id: $event_id}), (e:Entity {entity_id: $entity_id}) MERGE (e)-[r:PARTICIPATED_IN {role: $role}]->(ev) SET r.role = $role'\n",
      "INFO:neo4j.notifications:Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Statement.CartesianProduct} {category: PERFORMANCE} {title: This query builds a cartesian product between disconnected patterns.} {description: If a part of a query contains multiple disconnected patterns, this will build a cartesian product between all those parts. This may produce a large amount of data and slow down query processing. While occasionally intended, it may often be possible to reformulate the query that avoids the use of this cross product, perhaps by adding a relationship between the different parts or by using OPTIONAL MATCH (identifier is: (e))} {position: line: 1, column: 1, offset: 0} for query: 'MATCH (ev:Event {event_id: $event_id}), (e:Entity {entity_id: $entity_id}) MERGE (e)-[r:PARTICIPATED_IN {role: $role}]->(ev) SET r.role = $role'\n",
      "INFO:neo4j.notifications:Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Statement.CartesianProduct} {category: PERFORMANCE} {title: This query builds a cartesian product between disconnected patterns.} {description: If a part of a query contains multiple disconnected patterns, this will build a cartesian product between all those parts. This may produce a large amount of data and slow down query processing. While occasionally intended, it may often be possible to reformulate the query that avoids the use of this cross product, perhaps by adding a relationship between the different parts or by using OPTIONAL MATCH (identifier is: (e))} {position: line: 1, column: 1, offset: 0} for query: 'MATCH (ev:Event {event_id: $event_id}), (e:Entity {entity_id: $entity_id}) MERGE (e)-[r:PARTICIPATED_IN {role: $role}]->(ev) SET r.role = $role'\n",
      "INFO:neo4j.notifications:Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Statement.CartesianProduct} {category: PERFORMANCE} {title: This query builds a cartesian product between disconnected patterns.} {description: If a part of a query contains multiple disconnected patterns, this will build a cartesian product between all those parts. This may produce a large amount of data and slow down query processing. While occasionally intended, it may often be possible to reformulate the query that avoids the use of this cross product, perhaps by adding a relationship between the different parts or by using OPTIONAL MATCH (identifier is: (e))} {position: line: 1, column: 1, offset: 0} for query: 'MATCH (ev:Event {event_id: $event_id}), (e:Entity {entity_id: $entity_id}) MERGE (e)-[r:PARTICIPATED_IN {role: $role}]->(ev) SET r.role = $role'\n",
      "INFO:neo4j.notifications:Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Statement.CartesianProduct} {category: PERFORMANCE} {title: This query builds a cartesian product between disconnected patterns.} {description: If a part of a query contains multiple disconnected patterns, this will build a cartesian product between all those parts. This may produce a large amount of data and slow down query processing. While occasionally intended, it may often be possible to reformulate the query that avoids the use of this cross product, perhaps by adding a relationship between the different parts or by using OPTIONAL MATCH (identifier is: (e))} {position: line: 1, column: 1, offset: 0} for query: 'MATCH (ev:Event {event_id: $event_id}), (e:Entity {entity_id: $entity_id}) MERGE (e)-[r:PARTICIPATED_IN {role: $role}]->(ev) SET r.role = $role'\n",
      "INFO:RobustKG:KG load complete. report={'created_entities': 17, 'created_scenes': 4, 'created_events': 6, 'created_attributes': 3, 'created_emotions': 4, 'warnings': []}\n",
      "INFO:RobustKG:Driver closed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load report: {\n",
      "  \"created_entities\": 17,\n",
      "  \"created_scenes\": 4,\n",
      "  \"created_events\": 6,\n",
      "  \"created_attributes\": 3,\n",
      "  \"created_emotions\": 4,\n",
      "  \"warnings\": []\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # from robust_kg_loader import RobustKnowledgeGraphLoader\n",
    "    import json\n",
    "\n",
    "    # Neo4j connection\n",
    "    URI = \"neo4j://127.0.0.1:7687\"\n",
    "    USER = \"neo4j\"\n",
    "    PASS = \"rohitmukkala@sujal\"\n",
    "\n",
    "    # Use the final_data you created\n",
    "    pipeline_output = final_data\n",
    "\n",
    "    loader = RobustKnowledgeGraphLoader(URI, USER, PASS)\n",
    "    try:\n",
    "        report = loader.load_pipeline_output(\n",
    "            pipeline_output, \n",
    "            story_title=\"Fable\", \n",
    "            clear_story_first=True, \n",
    "            dry_run=False   # set True if you just want to test\n",
    "        )\n",
    "        print(\"Load report:\", json.dumps(report, indent=2))\n",
    "    finally:\n",
    "        loader.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afdb5fe-e9a8-4bf0-9da1-d25bd07a4992",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Story2KG (Python 3.10)",
   "language": "python",
   "name": "story2kg-ver-3-10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
